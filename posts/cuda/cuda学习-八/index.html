<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=auto data-palette=blue-gray><head><script src=/assets/init/bundle.min.8dd9996b0ee638d635dc27069afe0dd4f127d2c651a8a94ca43059331ce48a78.js integrity="sha256-jdmZaw7mONY13CcGmv4N1PEn0sZRqKlMpDBZMxzking=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>CUDA学习(八) - Kaster Mist's Blog</title>
<link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Hugo,Bootstrap,Blog Theme"><meta name=description content='本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。
零拷贝主机内存 上一章介绍了固定内存（页锁定内存），这种新型的主机内存能够确保不会交换出物理内存。我们通过cudaHostAlloc()来分配这种内存，并且传递参数cudaHostAllocDefault来获得默认的固定内存。本章会介绍在分配固定内存时可以使用其他参数值。除了cudaHostAllocDefault外，还可以传递的标志之一是cudaHostAllocMapped。通过cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别是当它不能从物理内存中交换出去或者重新定位时。但这种内存除了可以用于主机与GPU之间的内存复制外，还可以打破主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也被称为零拷贝内存。
通过零拷贝内存实现点积运算 通常，GPU只能访问GPU内存，而CPU也只能访问主机内存。但在某些环境中，打破这种规则或许能带来更好的效果。下面仍然给出一个矢量点积运算来进行介绍。这个版本不将输入矢量显式复制到GPU，而是使用零拷贝内存从GPU中直接访问数据。我们将编写两个函数，其中一个函数是对标准主机内存的测试，另一个函数将在GPU上执行归约运算，并使用零拷贝内存作为输入缓冲区和输出缓冲区。首先是点积运算的主机内存版本:
float malloc_test(int size){ //首先创建计时事件，然后分配输入缓冲区和输出缓冲区，并用数据填充输入缓冲区。 cudaEvent_t start, stop; float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;stop)); //在CPU上分配内存 a = (float*)malloc(size * sizeof(float)); b = (float*)malloc(size * sizeof(float)); partial_c = (float*)malloc(blocksPerGrid * sizeof(float)); //在GPU上分配内存 HANDLE_ERROR(cudaMalloc((void**)&amp;dev_a, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_b, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid * sizeof(float))); //用数据填充主机内存 for(int i = 0; i < size; i++){ a[i] = i; b[i] = i * 2; } //启动计时器，将输入数据复制到GPU，执行点积核函数，并将中间计算结果复制回主机。 HANDLE_ERROR(cudaEventRecord(start, 0)); //将数组“a“和”b”复制到GPU HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(float), cudaMemcpyHostToDevice)); HANDLE_ERROR(cudaMemcpy(dev_b, b, size * sizeof(float), cudaMemcpyHostToDevice)); dot<<<blocksPerGrid, threadsPerBlock>>>(size, dev_a, dev_b, dev_partial_c); //将数组“c”从GPU复制到CPU HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * sizeof(float), cudaMemcpyDeviceToHost)); //停止计时器 HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop)); //将中间计算结果相加起来，并释放输入缓冲区和输出缓冲区 //结束CPU上的计算 c = 0; for(int i = 0; i < blocksPerGrid; i++){ c += partial_c[i]; } HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaFree(dev_b)); HANDLE_ERROR(cudaFree(dev_partial_c)); //释放CPU上的内存 free(a); free(b); free(partial_c); //释放事件 HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); printf("Value calculated: %f\n", c); return elapsedTime; } 使用零拷贝内存的版本是非常类似的多，只是在内存分配上有所不同：'><meta name=robots content="index, follow"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA学习(八)"><meta name=twitter:description content='本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。
零拷贝主机内存 上一章介绍了固定内存（页锁定内存），这种新型的主机内存能够确保不会交换出物理内存。我们通过cudaHostAlloc()来分配这种内存，并且传递参数cudaHostAllocDefault来获得默认的固定内存。本章会介绍在分配固定内存时可以使用其他参数值。除了cudaHostAllocDefault外，还可以传递的标志之一是cudaHostAllocMapped。通过cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别是当它不能从物理内存中交换出去或者重新定位时。但这种内存除了可以用于主机与GPU之间的内存复制外，还可以打破主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也被称为零拷贝内存。
通过零拷贝内存实现点积运算 通常，GPU只能访问GPU内存，而CPU也只能访问主机内存。但在某些环境中，打破这种规则或许能带来更好的效果。下面仍然给出一个矢量点积运算来进行介绍。这个版本不将输入矢量显式复制到GPU，而是使用零拷贝内存从GPU中直接访问数据。我们将编写两个函数，其中一个函数是对标准主机内存的测试，另一个函数将在GPU上执行归约运算，并使用零拷贝内存作为输入缓冲区和输出缓冲区。首先是点积运算的主机内存版本:
float malloc_test(int size){ //首先创建计时事件，然后分配输入缓冲区和输出缓冲区，并用数据填充输入缓冲区。 cudaEvent_t start, stop; float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;stop)); //在CPU上分配内存 a = (float*)malloc(size * sizeof(float)); b = (float*)malloc(size * sizeof(float)); partial_c = (float*)malloc(blocksPerGrid * sizeof(float)); //在GPU上分配内存 HANDLE_ERROR(cudaMalloc((void**)&amp;dev_a, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_b, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid * sizeof(float))); //用数据填充主机内存 for(int i = 0; i < size; i++){ a[i] = i; b[i] = i * 2; } //启动计时器，将输入数据复制到GPU，执行点积核函数，并将中间计算结果复制回主机。 HANDLE_ERROR(cudaEventRecord(start, 0)); //将数组“a“和”b”复制到GPU HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(float), cudaMemcpyHostToDevice)); HANDLE_ERROR(cudaMemcpy(dev_b, b, size * sizeof(float), cudaMemcpyHostToDevice)); dot<<<blocksPerGrid, threadsPerBlock>>>(size, dev_a, dev_b, dev_partial_c); //将数组“c”从GPU复制到CPU HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * sizeof(float), cudaMemcpyDeviceToHost)); //停止计时器 HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop)); //将中间计算结果相加起来，并释放输入缓冲区和输出缓冲区 //结束CPU上的计算 c = 0; for(int i = 0; i < blocksPerGrid; i++){ c += partial_c[i]; } HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaFree(dev_b)); HANDLE_ERROR(cudaFree(dev_partial_c)); //释放CPU上的内存 free(a); free(b); free(partial_c); //释放事件 HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); printf("Value calculated: %f\n", c); return elapsedTime; } 使用零拷贝内存的版本是非常类似的多，只是在内存分配上有所不同：'><meta property="og:url" content="https://KasterMist.com/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AB/"><meta property="og:site_name" content="Kaster Mist's Blog"><meta property="og:title" content="CUDA学习(八)"><meta property="og:description" content="本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。
零拷贝主机内存 上一章介绍了固定内存（页锁定内存），这种新型的主机内存能够确保不会交换出物理内存。我们通过cudaHostAlloc()来分配这种内存，并且传递参数cudaHostAllocDefault来获得默认的固定内存。本章会介绍在分配固定内存时可以使用其他参数值。除了cudaHostAllocDefault外，还可以传递的标志之一是cudaHostAllocMapped。通过cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别是当它不能从物理内存中交换出去或者重新定位时。但这种内存除了可以用于主机与GPU之间的内存复制外，还可以打破主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也被称为零拷贝内存。
通过零拷贝内存实现点积运算 通常，GPU只能访问GPU内存，而CPU也只能访问主机内存。但在某些环境中，打破这种规则或许能带来更好的效果。下面仍然给出一个矢量点积运算来进行介绍。这个版本不将输入矢量显式复制到GPU，而是使用零拷贝内存从GPU中直接访问数据。我们将编写两个函数，其中一个函数是对标准主机内存的测试，另一个函数将在GPU上执行归约运算，并使用零拷贝内存作为输入缓冲区和输出缓冲区。首先是点积运算的主机内存版本:
float malloc_test(int size){ //首先创建计时事件，然后分配输入缓冲区和输出缓冲区，并用数据填充输入缓冲区。 cudaEvent_t start, stop; float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;amp;stop)); //在CPU上分配内存 a = (float*)malloc(size * sizeof(float)); b = (float*)malloc(size * sizeof(float)); partial_c = (float*)malloc(blocksPerGrid * sizeof(float)); //在GPU上分配内存 HANDLE_ERROR(cudaMalloc((void**)&amp;amp;dev_a, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;amp;dev_b, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;amp;dev_partial_c, blocksPerGrid * sizeof(float))); //用数据填充主机内存 for(int i = 0; i &amp;lt; size; i++){ a[i] = i; b[i] = i * 2; } //启动计时器，将输入数据复制到GPU，执行点积核函数，并将中间计算结果复制回主机。 HANDLE_ERROR(cudaEventRecord(start, 0)); //将数组“a“和”b”复制到GPU HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(float), cudaMemcpyHostToDevice)); HANDLE_ERROR(cudaMemcpy(dev_b, b, size * sizeof(float), cudaMemcpyHostToDevice)); dot&amp;lt;&amp;lt;&amp;lt;blocksPerGrid, threadsPerBlock&amp;gt;&amp;gt;&amp;gt;(size, dev_a, dev_b, dev_partial_c); //将数组“c”从GPU复制到CPU HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * sizeof(float), cudaMemcpyDeviceToHost)); //停止计时器 HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;amp;elapsedTime, start, stop)); //将中间计算结果相加起来，并释放输入缓冲区和输出缓冲区 //结束CPU上的计算 c = 0; for(int i = 0; i &amp;lt; blocksPerGrid; i++){ c += partial_c[i]; } HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaFree(dev_b)); HANDLE_ERROR(cudaFree(dev_partial_c)); //释放CPU上的内存 free(a); free(b); free(partial_c); //释放事件 HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); printf(&amp;#34;Value calculated: %f\n&amp;#34;, c); return elapsedTime; } 使用零拷贝内存的版本是非常类似的多，只是在内存分配上有所不同："><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-29T00:00:00+00:00"><meta property="article:tag" content="CUDA"><meta itemprop=name content="CUDA学习(八)"><meta itemprop=description content='本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。
零拷贝主机内存 上一章介绍了固定内存（页锁定内存），这种新型的主机内存能够确保不会交换出物理内存。我们通过cudaHostAlloc()来分配这种内存，并且传递参数cudaHostAllocDefault来获得默认的固定内存。本章会介绍在分配固定内存时可以使用其他参数值。除了cudaHostAllocDefault外，还可以传递的标志之一是cudaHostAllocMapped。通过cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别是当它不能从物理内存中交换出去或者重新定位时。但这种内存除了可以用于主机与GPU之间的内存复制外，还可以打破主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也被称为零拷贝内存。
通过零拷贝内存实现点积运算 通常，GPU只能访问GPU内存，而CPU也只能访问主机内存。但在某些环境中，打破这种规则或许能带来更好的效果。下面仍然给出一个矢量点积运算来进行介绍。这个版本不将输入矢量显式复制到GPU，而是使用零拷贝内存从GPU中直接访问数据。我们将编写两个函数，其中一个函数是对标准主机内存的测试，另一个函数将在GPU上执行归约运算，并使用零拷贝内存作为输入缓冲区和输出缓冲区。首先是点积运算的主机内存版本:
float malloc_test(int size){ //首先创建计时事件，然后分配输入缓冲区和输出缓冲区，并用数据填充输入缓冲区。 cudaEvent_t start, stop; float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;stop)); //在CPU上分配内存 a = (float*)malloc(size * sizeof(float)); b = (float*)malloc(size * sizeof(float)); partial_c = (float*)malloc(blocksPerGrid * sizeof(float)); //在GPU上分配内存 HANDLE_ERROR(cudaMalloc((void**)&amp;dev_a, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_b, size * sizeof(float))); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid * sizeof(float))); //用数据填充主机内存 for(int i = 0; i < size; i++){ a[i] = i; b[i] = i * 2; } //启动计时器，将输入数据复制到GPU，执行点积核函数，并将中间计算结果复制回主机。 HANDLE_ERROR(cudaEventRecord(start, 0)); //将数组“a“和”b”复制到GPU HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(float), cudaMemcpyHostToDevice)); HANDLE_ERROR(cudaMemcpy(dev_b, b, size * sizeof(float), cudaMemcpyHostToDevice)); dot<<<blocksPerGrid, threadsPerBlock>>>(size, dev_a, dev_b, dev_partial_c); //将数组“c”从GPU复制到CPU HANDLE_ERROR(cudaMemcpy(partial_c, dev_partial_c, blocksPerGrid * sizeof(float), cudaMemcpyDeviceToHost)); //停止计时器 HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop)); //将中间计算结果相加起来，并释放输入缓冲区和输出缓冲区 //结束CPU上的计算 c = 0; for(int i = 0; i < blocksPerGrid; i++){ c += partial_c[i]; } HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaFree(dev_b)); HANDLE_ERROR(cudaFree(dev_partial_c)); //释放CPU上的内存 free(a); free(b); free(partial_c); //释放事件 HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); printf("Value calculated: %f\n", c); return elapsedTime; } 使用零拷贝内存的版本是非常类似的多，只是在内存分配上有所不同：'><meta itemprop=datePublished content="2024-02-29T00:00:00+00:00"><meta itemprop=dateModified content="2024-02-29T00:00:00+00:00"><meta itemprop=wordCount content="898"><meta itemprop=keywords content="CUDA"><meta property="og:image" content="https://KasterMist.com/images/logo.png"><meta name=twitter:image content="https://KasterMist.com/images/logo.png"><meta property="og:image:alt" content="CUDA学习(八)"><meta name=twitter:image:alt content="CUDA学习(八)"><link rel=manifest href=/manifest.json><link data-precache rel=stylesheet href="/assets/main/bundle.min.bd72ac923f353ec9c246da4e3586d49ca15dc470e2e78be22d23c6e33696ceab.css" integrity="sha256-vXKskj81PsnCRtpONYbUnKFdxHDi54viLSPG4zaWzqs=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.eb914844636cd41f221f109e99c887bbc3b6b5ffb2af7c664b284cea2d1b54b7.css integrity="sha256-65FIRGNs1B8iHxCemciHu8O2tf+yr3xmSyhM6i0bVLc=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://KasterMist.com/><picture><img class=logo alt=Logo src="https://KasterMist.com/images/logo.webp?v=e4bf0b52e8123ceb71cdeade62eb59ce" loading=lazy width=956 height=956>
</picture>Main Page</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Main Page</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-6 col-xxl-auto"><a class="nav-link py-2 px-0 px-xxl-2" href=https://KasterMist.com/docs/><span class="menu-icon me-1"><i class="fas fa-fw fa-file"></i></span>Docs</a></li><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><h6 class=dropdown-header>Blog Menu Description</h6></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li><li class="nav-item col-6 col-xxl-auto"><a class="nav-link py-2 px-0 px-xxl-2" href=https://hbs.razonyang.com/v1/en/docs/ target=_blank rel="noopener noreferrer"><span class="menu-icon me-1"><i class="fas fa-fw fa-book"></i></span>Documentations</a></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/KasterMist title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-adjust" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class=mode-item data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class="mode-item active" data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/posts/>Posts</a></li><li class="breadcrumb-item active">CUDA学习(八)</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action btn-reward" role=button data-bs-toggle=modal data-bs-target=#rewardModal title="Buy me a coffee"><i class="fas fa-fw fa-coffee"></i>
</a><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-copyright" href=#post-copyright role=button aria-label=Copyright title=Copyright><i class="fas fa-fw fa-copyright"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">CUDA学习(八)</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2024-02-29 00:00:00 +0000 UTC.">February 29, 2024</span><span class="post-reading-time me-1 mb-1">5 min read</span><a href=/categories/tutorial/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Tutorial</a><a href=/tags/cuda/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">CUDA</a></div><div class="mt-2 mb-3 d-block d-xxl-none"><h2 class="text-surface mb-3">Contents</h2><div id=post-toc-container></div><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>本章将介绍如何分配和使用零拷贝内存(Zero-Copy Memory)，如何在同一个应用程序中使用多个GPU，以及如何分配和使用可移动的固定内存(Portable Pinned Memory)。</p><h2 id=零拷贝主机内存 data-numberify>零拷贝主机内存<a class="anchor ms-1" href=#零拷贝主机内存></a></h2><p>上一章介绍了固定内存（页锁定内存），这种新型的主机内存能够确保不会交换出物理内存。我们通过cudaHostAlloc()来分配这种内存，并且传递参数cudaHostAllocDefault来获得默认的固定内存。本章会介绍在分配固定内存时可以使用其他参数值。除了cudaHostAllocDefault外，还可以传递的标志之一是cudaHostAllocMapped。通过cudaHostAllocMapped分配的主机内存也是固定的，它与通过cudaHostAllocDefault分配的固定内存有着相同的属性，特别是当它不能从物理内存中交换出去或者重新定位时。但这种内存除了可以用于主机与GPU之间的内存复制外，还可以打破主机内存规则之一：可以在CUDA C核函数中直接访问这种类型的主机内存。由于这种内存不需要复制到GPU，因此也被称为零拷贝内存。</p><h3 id=通过零拷贝内存实现点积运算 data-numberify>通过零拷贝内存实现点积运算<a class="anchor ms-1" href=#通过零拷贝内存实现点积运算></a></h3><p>通常，GPU只能访问GPU内存，而CPU也只能访问主机内存。但在某些环境中，打破这种规则或许能带来更好的效果。下面仍然给出一个矢量点积运算来进行介绍。这个版本不将输入矢量显式复制到GPU，而是使用零拷贝内存从GPU中直接访问数据。我们将编写两个函数，其中一个函数是对标准主机内存的测试，另一个函数将在GPU上执行归约运算，并使用零拷贝内存作为输入缓冲区和输出缓冲区。首先是点积运算的主机内存版本:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>float</span> <span class=nf>malloc_test</span><span class=p>(</span><span class=kt>int</span> <span class=n>size</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=c1>//首先创建计时事件，然后分配输入缓冲区和输出缓冲区，并用数据填充输入缓冲区。
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=o>*</span><span class=n>partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在CPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>a</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>b</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>partial_c</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在GPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//用数据填充主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>size</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//启动计时器，将输入数据复制到GPU，执行点积核函数，并将中间计算结果复制回主机。
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=c1>//将数组“a“和”b”复制到GPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>dot</span><span class=o>&lt;&lt;&lt;</span><span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//将数组“c”从GPU复制到CPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>partial_c</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//停止计时器
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsedTime</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//将中间计算结果相加起来，并释放输入缓冲区和输出缓冲区
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//结束CPU上的计算
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>c</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>blocksPerGrid</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span> <span class=o>+=</span> <span class=n>partial_c</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_partial_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//释放CPU上的内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>free</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//释放事件
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Value calculated: %f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>使用零拷贝内存的版本是非常类似的多，只是在内存分配上有所不同：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>float</span> <span class=nf>cuda_host_alloc_test</span><span class=p>(</span><span class=kt>int</span> <span class=n>size</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=o>*</span><span class=n>partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在CPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaHostAllocWriteCombined</span> <span class=o>|</span> <span class=n>cudaHostAllocMapped</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>b</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaHostAllocWriteCombined</span> <span class=o>|</span> <span class=n>cudaHostAllocMapped</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaHostAllocMapped</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//用数据填充主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>size</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p>使用cudaHostAlloc()时，通过参数flags来指定内存的其他行为。cudaHostAllocMapped这个标志告诉运行时将从GPU中访问这块内存。这个标志意味着分配零拷贝内存。对于这两个输入缓冲区，我们还制定了标志cudaHostAllocWriteCombined。这个标志运行时应该将内存分配为“合并式写入（Write-Combined）”内存。这个标志并不会改变应用程序的功能，但却可以显著地提升GPU读取内存时的性能。然而，当CPU也要读取这块内存时，“合并式写入”会显得低效，因此在决定是否使用这个标志之前，必须首先考虑应用程序的可能访问模式。</p><p>在使用标志cudaHostAllocMapped来分配主机内存后，就可以从GPU中访问这块内存。然而，GPU的虚拟内存空间与CPU是不同的，因此在**GPU上访问它们与在CPU上访问它们有着不同的地址。调用cudaHostAlloc()将返回这块内存在CPU上的指针，因此需要调用cudaHostGetDevicePointer()来获得这块内存在GPU上的有效指针。**这些指针将被传递给核函数，并在随后由GPU对这块内存执行读取和写入等操作。即使dev_a、dev_b和dev_partial_c都位于主机上，但对于核函数来说，它们看起来就像GPU内存一样，这正是由于调用了cudaHostGetDevicePointer()。由于部分计算结果已经位于主机上，<strong>因此就不再需要通过cudaMemcpy()将它们从设备上复制回来。</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostGetDevicePointer</span><span class=p>(</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostGetDevicePointer</span><span class=p>(</span><span class=o>&amp;</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostGetDevicePointer</span><span class=p>(</span><span class=o>&amp;</span><span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>partial_c</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//启动计时器以及核函数
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>dot</span><span class=o>&lt;&lt;&lt;</span><span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=c1>//不再需要通过cudaMemcpy()将它们从设备上复制回来
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaThreadSynchronize</span><span class=p>());</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsedTime</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//结束GPU上的操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>c</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>blocksPerGrid</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span> <span class=o>+=</span> <span class=n>partial_c</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//在使用cudaHostAlloc()的点积运算代码中，唯一剩下的事情就是执行释放操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>partial_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//释放事件
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Value calculated: %f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>无论cudaHostAlloc()中使用什么标志，总是按照相同的方式来释放内存，即只需调用cudaFreeHost()。剩下的工作就是观察main()如何将这些代码片段组合在一起。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaDeviceProp</span> <span class=n>prop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>which</span> <span class=n>Device</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDevice</span><span class=p>(</span><span class=o>&amp;</span><span class=n>whichDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDeviceProperties</span><span class=p>(</span><span class=o>&amp;</span><span class=n>prop</span><span class=p>,</span> <span class=n>whichDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>prop</span><span class=p>.</span><span class=n>canMapHostMemory</span> <span class=o>!=</span> <span class=mi>1</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Device, cannot map memory. </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//如果设备支持零拷贝内存，那么接下来就是将运行时置入能分配零拷贝内存的状态
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//通过调用cudaSetDeviceFlags()来实现这个操作，并且传递标志值cudaDeviceMapHost来表示我们希望设备映射主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaSetDeviceFlags</span><span class=p>(</span><span class=n>cudaDeviceMapHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//运行两个测试，分别显示二者的执行时间，并推出应用程序：
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>float</span> <span class=n>elapsedTime</span> <span class=o>=</span> <span class=nf>malloc_test</span><span class=p>(</span><span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time using cudaMalloc: %3.1f ms</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>elapsedTime</span> <span class=o>=</span> <span class=nf>cuda_host_alloc_test</span><span class=p>(</span><span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time using cudaHostAlloc: %3.1f ms</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>下面是给出的核函数</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#define imin(a, b) (a &lt; b ? a : b)
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>N</span> <span class=o>=</span> <span class=mi>33</span> <span class=o>*</span> <span class=mi>1024</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>threadsPerBlock</span> <span class=o>=</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>blocksPerGrid</span> <span class=o>=</span> <span class=nf>imin</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=p>(</span><span class=n>N</span> <span class=o>+</span> <span class=n>threadsPerBlock</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>threadsPerBlock</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>dot</span><span class=p>(</span><span class=kt>int</span> <span class=n>size</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>c</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>__shared__</span> <span class=kt>float</span> <span class=n>cache</span><span class=p>[</span><span class=n>threadsPerBlock</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>cacheIndex</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>temp</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>size</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>temp</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>tid</span> <span class=o>+=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//设置cache中的值
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span><span class=p>]</span> <span class=o>=</span> <span class=n>temp</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//同步这个线程块中的线程
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//对于归约运算， threadsPerBlock必须为2的幂
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span><span class=p>(</span><span class=n>i</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>cacheIndex</span> <span class=o>&lt;</span> <span class=n>i</span><span class=p>){</span>
</span></span><span class=line><span class=cl>            <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span><span class=p>]</span> <span class=o>+=</span> <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span> <span class=o>+</span> <span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=n>i</span> <span class=o>/=</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>cacheIndex</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span><span class=p>[</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=n>cache</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=使用多个gpu data-numberify>使用多个GPU<a class="anchor ms-1" href=#使用多个gpu></a></h2><p>我们将把点积应用程序修改为使用多个GPU。为了降低编码难度，我们将在上一个结构中把计算点积所需的全部数据都相加起来。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>struct</span> <span class=n>DataStruct</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>deviceID</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>returnValue</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>这个结构包含了在计算点积时使用的设备标识，以及输入缓冲区的大小和指向两个输入缓冲区的指针a和b。最后，它还包含了一个成员用于保存a和b的点积运算结果。</p><p>要使用N个GPU，我们首先需要准确地知道N值是多少。因此，在应用程序的开头调用cudaDeviceCount()，从而判断在系统中安装了多少个支持CUDA的处理器。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>deviceCount</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDeviceCount</span><span class=p>(</span><span class=o>&amp;</span><span class=n>deviceCount</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>deviceCount</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;We need at least two compute 1.0 or greater devices, but only found %d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>deviceCount</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//为输入缓冲区分配标准的主机内存，并按照之前的方式填充
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=o>*</span> <span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_NULL</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>b</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)</span> <span class=o>*</span> <span class=n>N</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_NULL</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//用数据填充主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p>通过CUDA运行API来使用多个GPU时，要意识到每个GPU都需要由一个不同的CPU线程来控制。由于之前只是用了单个GPU，因此不需要担心这个问题。我们将多线程代码的大部分复杂性都移入到辅助代码文件book.h中。在精简了代码后，我们需要做的就是填充一个结构来执行计算。虽然在系统中可以有任意数量的GPU，但为了简单，在这里只使用两个：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=n>DataStruct</span> <span class=n>data</span><span class=p>[</span><span class=mi>2</span><span class=p>];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>deviceID</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>size</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>a</span> <span class=o>=</span> <span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>b</span> <span class=o>=</span> <span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>deviceID</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>size</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>a</span> <span class=o>=</span> <span class=n>a</span> <span class=o>+</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>b</span> <span class=o>=</span> <span class=n>b</span> <span class=o>+</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span></code></pre></div><p>我们将其中一个DataStruct变量传递给辅助函数start_thread()。此外，还将一个函数指针传给了start_thread()，新创建的线程将调用这个函数，这个示例中的线程函数为routine()。函数start_thread()将创建一个新的线程，这个线程将调用routine()，并将DataStruct变量作为参数传递进去。在应用程序的默认线程中也将调用routine()(因此只多创建了一个线程)。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=n>CUTThread</span> <span class=kr>thread</span> <span class=o>=</span> <span class=nf>start_thread</span><span class=p>(</span><span class=n>routine</span><span class=p>,</span> <span class=o>&amp;</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]));</span>
</span></span><span class=line><span class=cl>    <span class=nf>routine</span><span class=p>(</span><span class=o>&amp;</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>]));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//通过调用end_thread()，主应用程序线程将等待另一个线程执行完成。
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>end_thread</span><span class=p>(</span><span class=kr>thread</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//由于这两个线程都在main()的这个位置上执行完成，因此可以安全地释放内存并显示结果。
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>free</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	<span class=c1>//我们要将每个线程的计算结果相加起来。
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Value calculated: %f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>returnValue</span> <span class=o>+</span> <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>returnValue</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>在声明routine()时指定该函数带有一个void*参数，并返回void*，这样在start_thread()部分代码保持不变的情况下可以任意实现线程函数。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span><span class=o>*</span> <span class=nf>routine</span><span class=p>(</span><span class=kt>void</span> <span class=o>*</span><span class=n>pvoidData</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>DataStruct</span> <span class=o>*</span><span class=n>data</span> <span class=o>=</span> <span class=p>(</span><span class=n>DataStruct</span><span class=o>*</span><span class=p>)</span><span class=n>pvoidData</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaSetDevice</span><span class=p>(</span><span class=n>data</span><span class=o>-&gt;</span><span class=n>deviceID</span><span class=p>));</span>
</span></span></code></pre></div><p>除了调用cudaSetDevice()来指定希望使用的CUDA设备外，routine()的实现非常类似于之前提到的malloc_test()。我们为输入数据和临时计算结果分别分配了内存，随后调用cudaMemcpy()将每个输入数组复制到GPU。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>size</span> <span class=o>=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=o>*</span><span class=n>partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//在CPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>a</span> <span class=o>=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>b</span> <span class=o>=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>partial_c</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//在GPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//将数组“a”和“b”复制到GPU上
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//启动点积核函数，复制回计算结果，并且结束CPU上的操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>dot</span><span class=o>&lt;&lt;&lt;</span><span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//将数组“c”从GPU复制回CPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>partial_c</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//结束CPU上的操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>c</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>blocksPerGrid</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span> <span class=o>+=</span> <span class=n>partial_c</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_partial_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//释放CPU侧的内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>free</span><span class=p>(</span><span class=n>partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>-&gt;</span><span class=n>returnValue</span> <span class=o>=</span> <span class=n>c</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=可移动的固定内存 data-numberify>可移动的固定内存<a class="anchor ms-1" href=#可移动的固定内存></a></h2><p>我们可以将固定内存分配为可移动的，这意味着可以在主机线程之间移动这块内存，并且每个线程都将其视为固定内存。要达到这个目的，需要使用cudaHostAlloc()来分配内存，并且在调用时使用一个新的标志：cudaHostAllocPortable。这个标志可以与其他标志一起使用，例如cudaHostAllocWriteCombined和cudaHostAllocMapped。这意味着在分配主机内存时，可将其作为可移动、零拷贝以及合并式写入等的任意组合。</p><p>为了说明可移动固定内存的作用，我们将进一步修改使用多GPU的点积运算应用程序。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>deviceCount</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDeviceCount</span><span class=p>(</span><span class=o>&amp;</span><span class=n>deviceCount</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>deviceCount</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;We need at least two compute 1.0 or greater devices, but only found %d</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>deviceCount</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>cudaDeviceProp</span> <span class=n>prop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>2</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDeviceProperties</span><span class=p>(</span><span class=o>&amp;</span><span class=n>prop</span><span class=p>,</span> <span class=n>i</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>prop</span><span class=p>.</span><span class=n>canMapHostMemory</span> <span class=o>!=</span> <span class=mi>1</span><span class=p>){</span>
</span></span><span class=line><span class=cl>            <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Devide %d cannot map memory.</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>i</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaSetDevice</span><span class=p>(</span><span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaSetDeviceFlags</span><span class=p>(</span><span class=n>cudaDeviceMapHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaHostAllocWriteCombined</span> <span class=o>|</span> <span class=n>cudaHostAllocPortable</span> <span class=o>|</span> <span class=n>cudaHostAllocMapped</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>b</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaHostAllocWriteCombined</span> <span class=o>|</span> <span class=n>cudaHostAllocPortable</span> <span class=o>|</span> <span class=n>cudaHostAllocMapped</span><span class=p>));</span>
</span></span></code></pre></div><p>在使用cudaHostAlloc()分配页锁定内存时，首先要通过调用cudaSetDevice()来初始化设备。我们将新介绍的标志cudaHostAllocPortable传递给这两个内存分配操作。由于这些内存是在调用了cudaSetDevice(0)之后才分配的，因此，如果没有将这些内存指定为可移动的内存，那么只有第0个CUDA设备会把这些内存视为固定内存。</p><p>继续之前的应用程序，为输入矢量生成数据，并采用之前的示例的方式来准备DataStruct结构。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=c1>//用数据填充主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//为使用多线程做好准备
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>DataStruct</span> <span class=n>data</span><span class=p>[</span><span class=mi>2</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>deviceID</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>offset</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>size</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>a</span> <span class=o>=</span> <span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>b</span> <span class=o>=</span> <span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>deviceID</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>offset</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>size</span> <span class=o>=</span> <span class=n>N</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>a</span> <span class=o>=</span> <span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>b</span> <span class=o>=</span> <span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//创建第二个线程，并调用routine()开始在每个设备上执行计算
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>CUTThread</span> <span class=kr>thread</span> <span class=o>=</span> <span class=nf>start_thread</span><span class=p>(</span><span class=n>routine</span><span class=p>,</span> <span class=o>&amp;</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>]));</span>
</span></span><span class=line><span class=cl>    <span class=nf>routine</span><span class=p>(</span><span class=o>&amp;</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]));</span>
</span></span><span class=line><span class=cl>    <span class=nf>end_thread</span><span class=p>(</span><span class=kr>thread</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//由于主机内存时由CUDA运行时分配的，因此需要用cudaFreeHost()而不是free()来释放它
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Value calculated: %f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>returnValue</span> <span class=o>+</span> <span class=n>data</span><span class=p>[</span><span class=mi>1</span><span class=p>].</span><span class=n>returnValue</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>为了在多GPU应用程序中支持可移动的固定内存和零拷贝内存，我们需要对routine()的代码进行两处修改。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>void</span><span class=o>*</span> <span class=nf>routine</span><span class=p>(</span><span class=kt>void</span> <span class=o>*</span><span class=n>pvoidData</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>DataStruct</span> <span class=o>*</span><span class=n>data</span> <span class=o>=</span> <span class=p>(</span><span class=n>DataStruct</span><span class=o>*</span><span class=p>)</span><span class=n>pvoidData</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>data</span><span class=o>-&gt;</span><span class=n>deviceID</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaSetDevice</span><span class=p>(</span><span class=n>data</span><span class=o>-&gt;</span><span class=n>deviceID</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaSetDeviceFlags</span><span class=p>(</span><span class=n>cudaDeviceMapHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p>在多GPU版本的代码中，我们需要在routine()中调用cudaSetDevice()，从而确保每个线程控制一个不同的GPU。另一方面，在这个示例中，我们已经在主线程中调用了一次cudaSetDevice()。这么做的原因时为了在main()中分配固定内存。因此，我们只希望在还没有调用cudaSetDevice()的设备上调用cudaSetDevice()和cudaSetDeviceFlags()。也就是，如果devideID不是0，那么将调用这两个函数。虽然在第0个设备上再次调用这些函数会使代码更简洁，但是这种做法是错误的。一旦在某个线程上设置了这些设备，那么将不能再次调用cudaSetDevice()，即便传递的是相同的设备标识符。</p><p>除了使用可移动的固定内存外，我们还使用了零拷贝内存，一边从GPU中直接访问这些内存。因此，我们使用cudaHostGetDevicePointer()来获得主机内存的有效设备指针，这与前面零拷贝示例中采用的方法一样。然而，你可能会注意到使用了标准的GPU内存来保存临时计算结果。这块内存同样是通过cudaMalloc()来分配的。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>size</span> <span class=o>=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=o>*</span><span class=n>partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//在CPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>a</span> <span class=o>=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>b</span> <span class=o>=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>b</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>partial_c</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostGetDevicePointer</span><span class=p>(</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostGetDevicePointer</span><span class=p>(</span><span class=o>&amp;</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//计算GPU读取数据的偏移量“a”和“b”
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>dev_a</span> <span class=o>+=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>offset</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>dev_b</span> <span class=o>+=</span> <span class=n>data</span><span class=o>-&gt;</span><span class=n>offset</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>dot</span><span class=o>&lt;&lt;&lt;</span><span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//将数组“c“从GPU复制回CPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>partial_c</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//结束在CPU上的操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>c</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>blocksPerGrid</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span> <span class=o>+=</span> <span class=n>partial_c</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_partial_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//释放CPU上的内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>free</span><span class=p>(</span><span class=n>partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>-&gt;</span><span class=n>returnValue</span> <span class=o>=</span> <span class=n>c</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div></div><div class="modal fade" id=rewardModal tabindex=-1 aria-labelledby=rewardModalLabel aria-hidden=true><div class=modal-dialog><div class="modal-content surface"><div class=modal-header><h5 class="modal-title text-surface" id=rewardModalLabel><i class="fas fa-fw fa-coffee me-1"></i>Buy me a coffee</h5><a href=# data-bs-dismiss=modal class=btn-close aria-label=Close></a></div><div class=modal-body><ul class="nav nav-tabs mb-3" role=tablist><li class="nav-item text-nowrap" role=presentation><a class="nav-link active" id=reward-alipay-tab data-bs-toggle=tab href=#reward-alipay role=tab aria-controls=reward-alipay aria-selected=true><i class="fab fa-fw fa-alipay me-1"></i>Alipay</a></li><li class="nav-item text-nowrap" role=presentation><a class=nav-link id=reward-wechat-tab data-bs-toggle=tab href=#reward-wechat role=tab aria-controls=reward-wechat aria-selected=true><i class="fab fa-fw fa-weixin me-1"></i>WeChat</a></li></ul><div class=tab-content id=rewardTabContent><div class="tab-pane fade post-reward-content text-center show active" id=reward-alipay role=tabpanel aria-labelledby=reward-alipay-tab><img class="img-fluid post-reward-img" src=https://KasterMist.com/images/reward/alipay.jpg loading=lazy data-viewer-invisible></div><div class="tab-pane fade post-reward-content text-center show" id=reward-wechat role=tabpanel aria-labelledby=reward-wechat-tab><img class="img-fluid post-reward-img" src=https://KasterMist.com/images/reward/wechat.jpg loading=lazy data-viewer-invisible></div></div></div></div></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%83/>CUDA学习(七)</a></div><div class="post-nav post-next"><a href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B9%9D/>CUDA学习(九)</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><div class="post-copyright mb-3 row card component" id=post-copyright><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Copyright</h2></div><div class=card-body><a class="d-flex align-items-center flex-column" target=_blank rel="license noopener noreferrer" href=https://creativecommons.org/licenses/by-nc-nd/4.0/deed.en><span><i class="fab fa-fw fa-2x fa-creative-commons"></i><i class="fab fa-fw fa-2x fa-creative-commons-by"></i><i class="fab fa-fw fa-2x fa-creative-commons-nc"></i><i class="fab fa-fw fa-2x fa-creative-commons-nd"></i></span>
CC BY-NC-ND 4.0</a></div></div><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%83/>CUDA学习(七)</a><div class="post-meta mb-0">February 28, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AD/>CUDA学习(六)</a><div class="post-meta mb-0">February 27, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%BA%94/>CUDA学习(五)</a><div class="post-meta mb-0">February 23, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%9B%9B/>CUDA学习(四)</a><div class="post-meta mb-0">February 18, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%89/>CUDA学习(三)</a><div class="post-meta mb-0">February 12, 2024</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Kaster Mist" src="https://KasterMist.com/images/profile.webp?v=e4bf0b52e8123ceb71cdeade62eb59ce" loading=lazy data-viewer-invisible width=956 height=956></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Kaster Mist</div><div class=profile-company><i class="fas fa-fw fa-building"></i>ShonCloud</div><div class=profile-location><i class="fas fa-fw fa-map-marker-alt"></i>China</div><a class="profile-about text-primary" href=/about/><i class="fas fa-fw fa-user"></i>About</a><a class="profile-contact text-primary" href=/contact/><i class="fas fa-fw fa-question-circle"></i>Contact Us</a></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:KasterMist@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/KasterMist title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://www.linkedin.com/in/letian-xie-8a0886282/ title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/tutorial/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Tutorial>Tutorial
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/categories/note/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Note>Note
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/categories/draft/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Draft>Draft
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/cuda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=CUDA>CUDA
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/linux/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Linux>Linux
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/linux-command/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Linux Command">Linux Command
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/git/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Git>Git
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=计算机系统>计算机系统
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/hugo-bootstrap-skeleton/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Hugo Bootstrap Skeleton">Hugo Bootstrap Skeleton
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/macos-usage/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="MacOS Usage">MacOS Usage
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/math/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Math>Math
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/vscode/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=VsCode>VsCode
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">28</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt="Vim用法 (一)" src=https://KasterMist.com/images/logo/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim/>Vim用法 (一)</a><div class="post-meta mt-2"><span class=post-date>April 13, 2024</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0-%E4%BF%A1%E6%81%AF%E7%9A%84%E8%A1%A8%E7%A4%BA%E5%92%8C%E5%A4%84%E7%90%86/>计算机系统学习-信息的表示和处理</a><div class="post-meta mt-2"><span class=post-date>July 24, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0-%E5%89%8D%E8%A8%80/>计算机系统学习-前言</a><div class="post-meta mt-2"><span class=post-date>July 24, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/linear_algebra/linear_algrebra_1/>线性代数相关知识点</a><div class="post-meta mt-2"><span class=post-date>July 8, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt="Vim用法 (五) 深入理解Vim的寄存器" src=https://KasterMist.com/images/logo/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim-5/>Vim用法 (五) 深入理解Vim的寄存器</a><div class="post-meta mt-2"><span class=post-date>July 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt="Vim用法 (四) 代码跳转详解" src=https://KasterMist.com/images/logo/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim-4/>Vim用法 (四) 代码跳转详解</a><div class="post-meta mt-2"><span class=post-date>June 14, 2024</span></div></div></div></li></ul></div></div></div></div></div><div class="accordion post-toc d-none d-lg-block"><div class="accordion-item row mb-4 card component" id=postTOC><div class="card-header accordion-header"><h2 class="card-title fs-4 my-2 text-surface d-none d-lg-block">Contents</h2><a class="accordion-button d-lg-none mb-1 collapsed shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#post-toc aria-expanded=false aria-controls=post-toc>Contents</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block" id=post-toc><nav id=TableOfContents><ul><li><a href=#零拷贝主机内存>零拷贝主机内存</a><ul><li><a href=#通过零拷贝内存实现点积运算>通过零拷贝内存实现点积运算</a></li></ul></li><li><a href=#使用多个gpu>使用多个GPU</a></li><li><a href=#可移动的固定内存>可移动的固定内存</a></li></ul></nav></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="social-share mb-4 d-flex overflow-auto"><a class="btn-social-share d-flex flex-column align-items-center me-3" rel="noopener noreferrer" aria-label="Twitter Share Button" target=_blank href="https://twitter.com/intent/tweet?title=404%20Page%20not%20found&url=https%3a%2f%2fKasterMist.com%2f404.html"><i class="fab fa-2x fa-fw fa-twitter mb-2"></i> Twitter
</a><a class="btn-social-share d-flex flex-column align-items-center me-3" rel="noopener noreferrer" aria-label="Facebook Share Button" target=_blank href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fKasterMist.com%2f404.html"><i class="fab fa-2x fa-fw fa-facebook-f mb-2"></i> Facebook</a></div><hr class=mb-4><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Kaster Mist's Blog</p><p class="text-secondary mb-2"><small></small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2000-2024 Kaster Mist. All Rights Reserved.</small></div><div class="powered-by mb-2 text-secondary"><small>Build with ❤️ from the <a class=text-primary href=https://gohugo.io target=_blank rel="noopener noreferrer">Hugo</a> and the <a class=text-primary href=https://github.com/razonyang/hugo-theme-bootstrap target=_blank rel="noopener noreferrer">HBS</a> theme.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.81376e0753aa4dfad1dd162ed4ef8846e681861fb998c080b2dd6e6ae2fe1793.js integrity="sha256-gTduB1OqTfrR3RYu1O+IRuaBhh+5mMCAst1uauL+F5M=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.0a0d0099935beee41b7a7bf4543cd55e793e5f830a571b0794ef8c3602c5823c.js integrity="sha256-Cg0AmZNb7uQbenv0VDzVXnk+X4MKVxsHlO+MNgLFgjw=" crossorigin=anonymous defer></script><script src=/js/sw-register.js defer></script></body></html>