<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=auto data-palette=blue-gray><head><script src=/assets/init/bundle.min.42c0ed0dd5baeee307cec45b585e1906f653d7af06a8a6fed3b5e07dc0b1d906.js integrity="sha256-QsDtDdW67uMHzsRbWF4ZBvZT168GqKb+07XgfcCx2QY=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>CUDA学习(三) - Hugo Bootstrap Skeleton</title>
<link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Hugo,Bootstrap,Blog Theme"><meta name=description content="这一章将介绍线程块以及线程之间的通信机制和同步机制。
在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。
CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。
在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&#171;<N, M&#187;>总共启动的线程数量可以按照以下公式计算: $$ N个线程块 * M个线程/线程块 = N*M个并行线程 $$
使用线程实现GPU上的矢量求和 在之前的代码中，我们才去的时调用N个线程块，每个线程块对应一个线程add<<<N, 1>>>(dev_a, dev_b, dev_c);。
如果我们启动N个线程，并且所有线程都在一个线程块中，则可以表示为add<<<1, N>>>(dev_a, dev_b, dev_c);。此外，因为只有一个线程块，我们需要通过线程索引来对数据进行索引(而不是线程块索引)，需要将int tid = blockIdx.x;修改为int tid = threadIdx.x;
在GPU上对更长的矢量求和 对于启动核函数时每个线程块中的线程数量，硬件也进行了限制。具体来说，最大的线程数量不能超过设备树形结构中maxThreadsPerBlock域的值。对目前的GPU来说一个线程块最多有1024个线程。如果要通过并行线程对长度大于1024的矢量进行相加的话，就需要将线程与线程块结合起来才能实现。
此时，计算索引可以表示为:
int tid = threadIdx.x + blockIdx.x * blockDim.x; blockDim保存的事线程块中每一维的线程数量，由于使用的事一维线程块，因此只用到blockDim.x。
此外，gridDim是二维的，而blockDim是三维的。
假如我们使用多个线程块处理N个并行线程，每个线程块处理的线程数量为128，那样可以启动N/128个线程块。然而问题在于，当N小于128时，比如127，那么N/128等于0，此时将会启动0个线程块。所以我们希望这个除法能够向上取整。我们可以不用调用 ceil()函数，而是将计算改为(N+127)/N。因此，这个例子调用核函数可以写为:
add<<<(N + 127) / 128, 128>>>(dev_a, dev_b, dev_c); 当N不是128的整数倍时，将启动过多的线程。然而，在核函数中已经解决了这个问题。在访问输入数组和输出数组之前，必须检查线程的便宜是否位于0到N之间。
if(tid < N){ c[tid] = a[tid] + b[tid]; } 因此，当索引越过数组的边界时，核函数将自动停止执行计算。核函数不会对越过数组边界的内存进行读取或者写入。
在GPU上对任意长度的矢量求和 当矢量的长度很长时，我们可以让每一个线程执行多个矢量相加。例如
__global__ void add(int *a, int *b, int *c){ int tid = threadIdx."><meta name=robots content="index, follow"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA学习(三)"><meta name=twitter:description content="这一章将介绍线程块以及线程之间的通信机制和同步机制。
在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。
CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。
在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&#171;<N, M&#187;>总共启动的线程数量可以按照以下公式计算: $$ N个线程块 * M个线程/线程块 = N*M个并行线程 $$
使用线程实现GPU上的矢量求和 在之前的代码中，我们才去的时调用N个线程块，每个线程块对应一个线程add<<<N, 1>>>(dev_a, dev_b, dev_c);。
如果我们启动N个线程，并且所有线程都在一个线程块中，则可以表示为add<<<1, N>>>(dev_a, dev_b, dev_c);。此外，因为只有一个线程块，我们需要通过线程索引来对数据进行索引(而不是线程块索引)，需要将int tid = blockIdx.x;修改为int tid = threadIdx.x;
在GPU上对更长的矢量求和 对于启动核函数时每个线程块中的线程数量，硬件也进行了限制。具体来说，最大的线程数量不能超过设备树形结构中maxThreadsPerBlock域的值。对目前的GPU来说一个线程块最多有1024个线程。如果要通过并行线程对长度大于1024的矢量进行相加的话，就需要将线程与线程块结合起来才能实现。
此时，计算索引可以表示为:
int tid = threadIdx.x + blockIdx.x * blockDim.x; blockDim保存的事线程块中每一维的线程数量，由于使用的事一维线程块，因此只用到blockDim.x。
此外，gridDim是二维的，而blockDim是三维的。
假如我们使用多个线程块处理N个并行线程，每个线程块处理的线程数量为128，那样可以启动N/128个线程块。然而问题在于，当N小于128时，比如127，那么N/128等于0，此时将会启动0个线程块。所以我们希望这个除法能够向上取整。我们可以不用调用 ceil()函数，而是将计算改为(N+127)/N。因此，这个例子调用核函数可以写为:
add<<<(N + 127) / 128, 128>>>(dev_a, dev_b, dev_c); 当N不是128的整数倍时，将启动过多的线程。然而，在核函数中已经解决了这个问题。在访问输入数组和输出数组之前，必须检查线程的便宜是否位于0到N之间。
if(tid < N){ c[tid] = a[tid] + b[tid]; } 因此，当索引越过数组的边界时，核函数将自动停止执行计算。核函数不会对越过数组边界的内存进行读取或者写入。
在GPU上对任意长度的矢量求和 当矢量的长度很长时，我们可以让每一个线程执行多个矢量相加。例如
__global__ void add(int *a, int *b, int *c){ int tid = threadIdx."><meta property="og:url" content="https://KasterMist.com/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%89/"><meta property="og:site_name" content="Hugo Bootstrap Skeleton"><meta property="og:title" content="CUDA学习(三)"><meta property="og:description" content="这一章将介绍线程块以及线程之间的通信机制和同步机制。
在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。
CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。
在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&amp;laquo;&amp;lt;N, M&amp;raquo;&amp;gt;总共启动的线程数量可以按照以下公式计算: $$ N个线程块 * M个线程/线程块 = N*M个并行线程 $$
使用线程实现GPU上的矢量求和 在之前的代码中，我们才去的时调用N个线程块，每个线程块对应一个线程add&amp;lt;&amp;lt;&amp;lt;N, 1&amp;gt;&amp;gt;&amp;gt;(dev_a, dev_b, dev_c);。
如果我们启动N个线程，并且所有线程都在一个线程块中，则可以表示为add&amp;lt;&amp;lt;&amp;lt;1, N&amp;gt;&amp;gt;&amp;gt;(dev_a, dev_b, dev_c);。此外，因为只有一个线程块，我们需要通过线程索引来对数据进行索引(而不是线程块索引)，需要将int tid = blockIdx.x;修改为int tid = threadIdx.x;
在GPU上对更长的矢量求和 对于启动核函数时每个线程块中的线程数量，硬件也进行了限制。具体来说，最大的线程数量不能超过设备树形结构中maxThreadsPerBlock域的值。对目前的GPU来说一个线程块最多有1024个线程。如果要通过并行线程对长度大于1024的矢量进行相加的话，就需要将线程与线程块结合起来才能实现。
此时，计算索引可以表示为:
int tid = threadIdx.x + blockIdx.x * blockDim.x; blockDim保存的事线程块中每一维的线程数量，由于使用的事一维线程块，因此只用到blockDim.x。
此外，gridDim是二维的，而blockDim是三维的。
假如我们使用多个线程块处理N个并行线程，每个线程块处理的线程数量为128，那样可以启动N/128个线程块。然而问题在于，当N小于128时，比如127，那么N/128等于0，此时将会启动0个线程块。所以我们希望这个除法能够向上取整。我们可以不用调用 ceil()函数，而是将计算改为(N+127)/N。因此，这个例子调用核函数可以写为:
add&amp;lt;&amp;lt;&amp;lt;(N + 127) / 128, 128&amp;gt;&amp;gt;&amp;gt;(dev_a, dev_b, dev_c); 当N不是128的整数倍时，将启动过多的线程。然而，在核函数中已经解决了这个问题。在访问输入数组和输出数组之前，必须检查线程的便宜是否位于0到N之间。
if(tid &amp;lt; N){ c[tid] = a[tid] + b[tid]; } 因此，当索引越过数组的边界时，核函数将自动停止执行计算。核函数不会对越过数组边界的内存进行读取或者写入。
在GPU上对任意长度的矢量求和 当矢量的长度很长时，我们可以让每一个线程执行多个矢量相加。例如
__global__ void add(int *a, int *b, int *c){ int tid = threadIdx."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-12T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-12T00:00:00+00:00"><meta property="article:tag" content="CUDA"><meta itemprop=name content="CUDA学习(三)"><meta itemprop=description content="这一章将介绍线程块以及线程之间的通信机制和同步机制。
在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。
CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。
在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&#171;<N, M&#187;>总共启动的线程数量可以按照以下公式计算: $$ N个线程块 * M个线程/线程块 = N*M个并行线程 $$
使用线程实现GPU上的矢量求和 在之前的代码中，我们才去的时调用N个线程块，每个线程块对应一个线程add<<<N, 1>>>(dev_a, dev_b, dev_c);。
如果我们启动N个线程，并且所有线程都在一个线程块中，则可以表示为add<<<1, N>>>(dev_a, dev_b, dev_c);。此外，因为只有一个线程块，我们需要通过线程索引来对数据进行索引(而不是线程块索引)，需要将int tid = blockIdx.x;修改为int tid = threadIdx.x;
在GPU上对更长的矢量求和 对于启动核函数时每个线程块中的线程数量，硬件也进行了限制。具体来说，最大的线程数量不能超过设备树形结构中maxThreadsPerBlock域的值。对目前的GPU来说一个线程块最多有1024个线程。如果要通过并行线程对长度大于1024的矢量进行相加的话，就需要将线程与线程块结合起来才能实现。
此时，计算索引可以表示为:
int tid = threadIdx.x + blockIdx.x * blockDim.x; blockDim保存的事线程块中每一维的线程数量，由于使用的事一维线程块，因此只用到blockDim.x。
此外，gridDim是二维的，而blockDim是三维的。
假如我们使用多个线程块处理N个并行线程，每个线程块处理的线程数量为128，那样可以启动N/128个线程块。然而问题在于，当N小于128时，比如127，那么N/128等于0，此时将会启动0个线程块。所以我们希望这个除法能够向上取整。我们可以不用调用 ceil()函数，而是将计算改为(N+127)/N。因此，这个例子调用核函数可以写为:
add<<<(N + 127) / 128, 128>>>(dev_a, dev_b, dev_c); 当N不是128的整数倍时，将启动过多的线程。然而，在核函数中已经解决了这个问题。在访问输入数组和输出数组之前，必须检查线程的便宜是否位于0到N之间。
if(tid < N){ c[tid] = a[tid] + b[tid]; } 因此，当索引越过数组的边界时，核函数将自动停止执行计算。核函数不会对越过数组边界的内存进行读取或者写入。
在GPU上对任意长度的矢量求和 当矢量的长度很长时，我们可以让每一个线程执行多个矢量相加。例如
__global__ void add(int *a, int *b, int *c){ int tid = threadIdx."><meta itemprop=datePublished content="2024-02-12T00:00:00+00:00"><meta itemprop=dateModified content="2024-02-12T00:00:00+00:00"><meta itemprop=wordCount content="487"><meta itemprop=keywords content="CUDA"><meta property="og:image" content="https://KasterMist.com/images/logo.png"><meta name=twitter:image content="https://KasterMist.com/images/logo.png"><meta property="og:image:alt" content="CUDA学习(三)"><meta name=twitter:image:alt content="CUDA学习(三)"><link rel=manifest href=/manifest.json><link data-precache rel=stylesheet href="/assets/main/bundle.min.c91211bab9a27752a04f0e67395e2f71bac30e8143bec4463bc91b3705056a70.css" integrity="sha256-yRIRurmid1KgTw5nOV4vcbrDDoFDvsRGO8kbNwUFanA=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.eb914844636cd41f221f109e99c887bbc3b6b5ffb2af7c664b284cea2d1b54b7.css integrity="sha256-65FIRGNs1B8iHxCemciHu8O2tf+yr3xmSyhM6i0bVLc=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://KasterMist.com/><picture><img class=logo alt=Logo src="https://KasterMist.com/images/logo.webp?v=7b75fc81c95df67e3796d1b804da443a" loading=lazy width=956 height=956>
</picture>Main Page</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Main Page</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-6 col-xxl-auto"><a class="nav-link py-2 px-0 px-xxl-2" href=https://KasterMist.com/docs/><span class="menu-icon me-1"><i class="fas fa-fw fa-file"></i></span>Docs</a></li><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><h6 class=dropdown-header>Blog Menu Description</h6></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li><li class="nav-item col-6 col-xxl-auto"><a class="nav-link py-2 px-0 px-xxl-2" href=https://hbs.razonyang.com/v1/en/docs/ target=_blank rel="noopener noreferrer"><span class="menu-icon me-1"><i class="fas fa-fw fa-book"></i></span>Documentations</a></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/KasterMist title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-adjust" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class=mode-item data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class="mode-item active" data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/posts/>Posts</a></li><li class="breadcrumb-item active">CUDA学习(三)</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action btn-reward" role=button data-bs-toggle=modal data-bs-target=#rewardModal title="Buy me a coffee"><i class="fas fa-fw fa-coffee"></i>
</a><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-copyright" href=#post-copyright role=button aria-label=Copyright title=Copyright><i class="fas fa-fw fa-copyright"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">CUDA学习(三)</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2024-02-12 00:00:00 +0000 UTC.">February 12, 2024</span><span class="post-reading-time me-1 mb-1">3 min read</span><a href=/categories/tutorial/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Tutorial</a><a href=/tags/cuda/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">CUDA</a></div><div class="mt-2 mb-3 d-block d-xxl-none"><h2 class="text-surface mb-3">Contents</h2><div id=post-toc-container></div><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>这一章将介绍线程块以及线程之间的通信机制和同步机制。</p><p>在GPU启动并行代码的实现方法是告诉CUDA运行时启动核函数的多个并行副本。我们将这些并行副本称为线程块(Block)。</p><p>CUDA运行时将把这些线程块分解为多个线程。当需要启动多个并行线程块时，只需将尖括号中的第一个参数由1改为想要启动的线程块数量。</p><p>在尖括号中，第二个参数表示CUDA运行时在每个线程块中创建的线程数量。假设尖括号中的变量为&#171;&lt;N, M&#187;>总共启动的线程数量可以按照以下公式计算:
$$
N个线程块 * M个线程/线程块 = N*M个并行线程
$$</p><h3 id=使用线程实现gpu上的矢量求和 data-numberify>使用线程实现GPU上的矢量求和<a class="anchor ms-1" href=#使用线程实现gpu上的矢量求和></a></h3><p>在之前的代码中，我们才去的时调用N个线程块，每个线程块对应一个线程<code>add&lt;&lt;&lt;N, 1>>>(dev_a, dev_b, dev_c);</code>。</p><p>如果我们启动N个线程，并且所有线程都在一个线程块中，则可以表示为<code>add&lt;&lt;&lt;1, N>>>(dev_a, dev_b, dev_c);</code>。此外，因为只有一个线程块，我们需要通过线程索引来对数据进行索引(而不是线程块索引)，需要将<code>int tid = blockIdx.x;</code>修改为<code>int tid = threadIdx.x;</code></p><h3 id=在gpu上对更长的矢量求和 data-numberify>在GPU上对更长的矢量求和<a class="anchor ms-1" href=#在gpu上对更长的矢量求和></a></h3><p>对于启动核函数时每个线程块中的线程数量，硬件也进行了限制。具体来说，最大的线程数量不能超过设备树形结构中maxThreadsPerBlock域的值。对目前的GPU来说一个线程块最多有1024个线程。如果要通过并行线程对长度大于1024的矢量进行相加的话，就需要将线程与线程块结合起来才能实现。</p><p>此时，计算索引可以表示为:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span></code></pre></div><p>blockDim保存的事线程块中每一维的线程数量，由于使用的事一维线程块，因此只用到blockDim.x。</p><p>此外，gridDim是二维的，而blockDim是三维的。</p><p>假如我们使用多个线程块处理N个并行线程，每个线程块处理的线程数量为128，那样可以启动N/128个线程块。然而问题在于，当N小于128时，比如127，那么N/128等于0，此时将会启动0个线程块。所以我们希望这个除法能够向上取整。我们可以不用调用 ceil()函数，而是将计算改为(N+127)/N。因此，这个例子调用核函数可以写为:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>add</span><span class=o>&lt;&lt;&lt;</span><span class=p>(</span><span class=n>N</span> <span class=o>+</span> <span class=mi>127</span><span class=p>)</span> <span class=o>/</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_c</span><span class=p>);</span>
</span></span></code></pre></div><p>当N不是128的整数倍时，将启动过多的线程。然而，在核函数中已经解决了这个问题。在访问输入数组和输出数组之前，必须检查线程的便宜是否位于0到N之间。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>if</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>	<span class=n>c</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>因此，当索引越过数组的边界时，核函数将自动停止执行计算。核函数不会对越过数组边界的内存进行读取或者写入。</p><h3 id=在gpu上对任意长度的矢量求和 data-numberify>在GPU上对任意长度的矢量求和<a class="anchor ms-1" href=#在gpu上对任意长度的矢量求和></a></h3><p>当矢量的长度很长时，我们可以让每一个线程执行多个矢量相加。例如</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>add</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>c</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>tid</span> <span class=o>+=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>当每个线程计算完当前索引上的任务后，接着就需要对索引进行递增，其中递增的步长为线程格中正在运行的线程数量。这个数值等于每个线程块中的线程数量乘上线程格中线程块的数量，即blockDim.x * gridDim.x。</p><h3 id=共享内存和同步 data-numberify>共享内存和同步<a class="anchor ms-1" href=#共享内存和同步></a></h3><p>CUDA C编译器对共享内存中的变量与普通变量分别采取不同的处理方式。对于在GPU上启动的每个线程块，CUDA C编译器都将创建该变量的一个副本，线程块中的每个线程都共享这块内存，但线程却无法看到也不能修改其他线程块的变量副本。这就实现了一个非常好的方式，<strong>使得一个线程块中的多个线程能够在计算上进行通信和协作</strong>。</p><p>而且，共享内存缓冲区驻留在物理GPU上，而不是驻留在GPU之外的系统内存中。因此，<strong>在访问共享内存时的延迟要远远低于访问普通缓冲区的延迟</strong>，使得共享内存像每个线程块的高速缓存或者中间结果暂存器那样高效。</p><p>如果想要实现线程之间通信，那么还需要一种机制来实现线程之间的同步。例如，如果线程A将一个值写入到共享内存，并且我们希望线程B对这个值进行一些操作，那么只有当线程A的写入操作完成之后，线程B才能开始执行它的操作。如果没有同步，那么将发生竞态条件(race condition)。</p><p>下面将通过一个矢量的点积运算来详细介绍共享内存和同步。矢量点积运算为矢量相乘结束后将值相加起来以得到一个标量输出值。例如对两个包含4个元素的矢量进行点积运算:
$$
(x_1, x_2, x_3, x_4) * (y_1, y_2, y_3, y_4) = x_1y_1 + x_2y_2 + x_3y_3 + x_4y_4
$$
由于最终结果是所有乘积的总和，因此每个线程要保存它所计算的乘积的加和。下面代码实现了点积函数的第一个步骤:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;../common/book.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#define imin(a, b) (a &lt; b ? a : b)
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>N</span> <span class=o>=</span> <span class=mi>33</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>threadsPerBlock</span> <span class=o>=</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>dot</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>c</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>__shared__</span> <span class=kt>float</span> <span class=n>cache</span><span class=p>[</span><span class=n>threadsPerBlock</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>cacheIndex</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>temp</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>temp</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>tid</span> <span class=o>+=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//设置cache中相应位置上的值
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span><span class=p>]</span> <span class=o>=</span> <span class=n>temp</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>代码中声明了一个共享内存缓冲区，名字为cache。这个缓冲区将保存每个线程计算的加和值。我们将cache数组的大小声明为threadsPerBlock，这样线程块中每个线程都能将它计算的临时结果保存到某个位置上。之前在分配全局内存时，我们为每个执行核函数的线程都分配了足够的内存，即线程块的数量乘以threadsPerBlock。但对于共享变量来说，由于编译器将为每个线程块生成共享变量的一个副本，因此只需根据线程块中线程的数量来分配内存。</p><p>我们需要将cache中所有的值相加起来。在执行这个运算时，需要通过一个线程来读取保存在cache中的值。由于race condition，我们需要使用下面的代码来确保对所有共享数组cache[]的写入操作在读组cache之前完成:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>//对线程块中的线程进行同步
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>__syncthreads</span><span class=p>();</span>
</span></span></code></pre></div><p>这个函数调用将确保线程块中的每个线程都执行完__syncthreads()前面的语句后，才会执行下一条语句。</p><p>这时，我们可以将其中的值相加起来(称为归约Reduction)。代码的基本思想是每个线程将cache[]中的两个值相加起来，然后将结果保存回cache[]。由于每个线程都将两个值合并为一个值，那么在完成这个步骤后，得到的结果数量就是计算开始时数值数量的一半。下一个步骤中我们对这一半数值执行相同的操作，在将这种操作执行log2(threadsPerBlock)步骤后，就能得到cache[]中所有值的总和。对于这个示例来说，我们在每个线程块中使用了256个线程，因此需要8次迭代将cache[]中的256个值归约为1个值。这个归约过程的实现可以表示为以下代码:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>//对于归约运算来说，以下代码要求threadsPerBlock必须时2的指数
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>while</span><span class=p>(</span><span class=n>i</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>cacheIndex</span> <span class=o>&lt;</span> <span class=n>i</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span><span class=p>]</span> <span class=o>+=</span> <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span> <span class=o>+</span> <span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=n>i</span> <span class=o>/=</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>再结束了while()循环后，每个线程块都得到了一个值，这个值位于cache[]的第一个元素中，并且就等于该线程块中两两元素乘积的加和。然后，我们将这个值保存到全局内存并结束核函数:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>if</span><span class=p>(</span><span class=n>cacheIndex</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>c</span><span class=p>[</span><span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=n>cache</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>只让cacheIndex为0的线程执行保存操作时因为每个线程块只有一个值写入到全局内存，因此每个线程块只需要一个线程来执行这个操作。最后，由于每个线程块都只写入一个值到全局数据c[]中，因此可以通过blockIdx来索引这个值。</p><p>点积运算的最后一个步骤就是计算c[]中所有元素的总和。像GPU这种大规模的并行机器在执行最后的归约步骤时，通常会浪费计算资源，因为此时的数据集往往会非常小。因此，我们可以将执行控制返回给主机，并且由CPU来完成最后一个加法步骤。</p><p>下面给出了完整的代码实现:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;../common/book.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#define imin(a, b) (a &lt; b? a : b)
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>N</span> <span class=o>=</span> <span class=mi>33</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>threadsPerBlock</span> <span class=o>=</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>int</span> <span class=n>blocksPerGrid</span> <span class=o>=</span> <span class=nf>imin</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=p>(</span><span class=n>N</span> <span class=o>+</span> <span class=n>threadsPerBlock</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>threadsPerBlock</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>dot</span><span class=p>(</span><span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>float</span> <span class=o>*</span><span class=n>c</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=n>__shared__</span> <span class=kt>float</span> <span class=n>cache</span><span class=p>[</span><span class=n>threadsPerBlock</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>tid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>cacheIndex</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>temp</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span><span class=p>(</span><span class=n>tid</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>temp</span> <span class=o>+=</span> <span class=n>a</span><span class=p>[</span><span class=n>tid</span><span class=p>]</span> <span class=o>*</span> <span class=n>b</span><span class=p>[</span><span class=n>tid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=n>tid</span> <span class=o>+=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>gridDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//设置cache中相应位置上的值
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span><span class=p>]</span> <span class=o>=</span> <span class=n>temp</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//对线程块中的线程进行同步
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>__syncthreads</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//对于归约来说，以下代码要求threadsPerBlock必须是2的指数
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span><span class=p>(</span><span class=n>i</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>cacheIndex</span> <span class=o>&lt;</span> <span class=n>i</span><span class=p>){</span>
</span></span><span class=line><span class=cl>            <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span><span class=p>]</span> <span class=o>+=</span> <span class=n>cache</span><span class=p>[</span><span class=n>cacheIndex</span> <span class=o>+</span> <span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=nf>__syncthreads</span><span class=p>();</span> <span class=c1>//循环中更新了变量cache，所以需要在下一次循环前进行同步。该同步语句需要所有的线程都必须运行才行。如果有线程不能运行这一处代码，会导致其他线程永远等待。
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>i</span> <span class=o>/=</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>cacheIndex</span> <span class=o>==</span> <span class=mi>0</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span><span class=p>[</span><span class=n>blockIndex</span><span class=p>.</span><span class=n>x</span><span class=p>]</span> <span class=o>=</span> <span class=n>cache</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=o>*</span><span class=n>partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=o>*</span><span class=n>dev_c</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_partial_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在CPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>a</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span> <span class=nf>malloc</span><span class=p>(</span><span class=n>N</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>b</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span> <span class=nf>malloc</span><span class=p>(</span><span class=n>N</span><span class=o>*</span><span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>partial_c</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span> <span class=nf>malloc</span><span class=p>(</span><span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在GPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//填充主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span> <span class=o>*</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//将数组&#34;a&#34;和&#34;b&#34;复制到GPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>b</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>dot</span><span class=o>&lt;&lt;&lt;</span><span class=n>blocksPerGrid</span><span class=p>,</span> <span class=n>threadsPerBlock</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//将数组&#34;c&#34;从GPU复制到CPU
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>partial_c</span><span class=p>,</span> <span class=n>dev_partial_c</span><span class=p>,</span> <span class=n>blocksPerGrid</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在CPU上完成最终的求和运算
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>c</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>blocksPerGrid</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span> <span class=o>+=</span> <span class=n>partial_c</span><span class=p>[</span><span class=n>i</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=cp>#define sum_squares(x) (x * (x + 1) * (2 * x + 1) / 6)
</span></span></span><span class=line><span class=cl><span class=cp></span>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Does GPU value %.6g = %.6g? </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=nf>sum_square</span><span class=p>((</span><span class=kt>float</span><span class=p>)</span> <span class=p>(</span><span class=n>N</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//释放GPU上的内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//释放CPU上的内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>free</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>b</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>partial_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div></div><div class="modal fade" id=rewardModal tabindex=-1 aria-labelledby=rewardModalLabel aria-hidden=true><div class=modal-dialog><div class="modal-content surface"><div class=modal-header><h5 class="modal-title text-surface" id=rewardModalLabel><i class="fas fa-fw fa-coffee me-1"></i>Buy me a coffee</h5><a href=# data-bs-dismiss=modal class=btn-close aria-label=Close></a></div><div class=modal-body><ul class="nav nav-tabs mb-3" role=tablist><li class="nav-item text-nowrap" role=presentation><a class="nav-link active" id=reward-alipay-tab data-bs-toggle=tab href=#reward-alipay role=tab aria-controls=reward-alipay aria-selected=true><i class="fab fa-fw fa-alipay me-1"></i>Alipay</a></li><li class="nav-item text-nowrap" role=presentation><a class=nav-link id=reward-wechat-tab data-bs-toggle=tab href=#reward-wechat role=tab aria-controls=reward-wechat aria-selected=true><i class="fab fa-fw fa-weixin me-1"></i>WeChat</a></li></ul><div class=tab-content id=rewardTabContent><div class="tab-pane fade post-reward-content text-center show active" id=reward-alipay role=tabpanel aria-labelledby=reward-alipay-tab><img class="img-fluid post-reward-img" src=https://KasterMist.com/images/reward/alipay.jpg loading=lazy data-viewer-invisible></div><div class="tab-pane fade post-reward-content text-center show" id=reward-wechat role=tabpanel aria-labelledby=reward-wechat-tab><img class="img-fluid post-reward-img" src=https://KasterMist.com/images/reward/wechat.jpg loading=lazy data-viewer-invisible></div></div></div></div></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%BA%8C/>CUDA学习(二)</a></div><div class="post-nav post-next"><a href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%9B%9B/>CUDA学习(四)</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><div class="post-copyright mb-3 row card component" id=post-copyright><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Copyright</h2></div><div class=card-body><a class="d-flex align-items-center flex-column" target=_blank rel="license noopener noreferrer" href=https://creativecommons.org/licenses/by-nc-nd/4.0/deed.en><span><i class="fab fa-fw fa-2x fa-creative-commons"></i><i class="fab fa-fw fa-2x fa-creative-commons-by"></i><i class="fab fa-fw fa-2x fa-creative-commons-nc"></i><i class="fab fa-fw fa-2x fa-creative-commons-nd"></i></span>
CC BY-NC-ND 4.0</a></div></div><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%BA%8C/>CUDA学习(二)</a><div class="post-meta mb-0">February 8, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%80/>CUDA学习(一)</a><div class="post-meta mb-0">February 4, 2024</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Kaster Mist" src="https://KasterMist.com/images/profile.webp?v=7b75fc81c95df67e3796d1b804da443a" loading=lazy data-viewer-invisible width=956 height=956></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Kaster Mist</div><div class=profile-company><i class="fas fa-fw fa-building"></i>ShonCloud</div><div class=profile-location><i class="fas fa-fw fa-map-marker-alt"></i>China</div><a class="profile-about text-primary" href=/about/><i class="fas fa-fw fa-user"></i>About</a><a class="profile-contact text-primary" href=/contact/><i class="fas fa-fw fa-question-circle"></i>Contact Us</a></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:KasterMist@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/KasterMist title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://www.linkedin.com/in/letian-xie-8a0886282/ title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/tutorial/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Tutorial>Tutorial
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/categories/note/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Note>Note
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/categories/draft/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Draft>Draft
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/cuda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=CUDA>CUDA
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/tags/linux/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Linux>Linux
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/linux-command/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Linux Command">Linux Command
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/git/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Git>Git
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/hugo-bootstrap-skeleton/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Hugo Bootstrap Skeleton">Hugo Bootstrap Skeleton
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/vscode/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=VsCode>VsCode
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">15</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt=Vim src=https://KasterMist.com/images/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim/>Vim</a><div class="post-meta mt-2"><span class=post-date>April 13, 2024</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/git/git_tutorial_1/>Git 学习 (一)</a><div class="post-meta mt-2"><span class=post-date>May 14, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/hugo_theme_usage_notes/hugo_bootstrap_skeleton/>Hugo Bootstrap Skeleton Notes</a><div class="post-meta mt-2"><span class=post-date>May 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt="Vscode 插件: C/C++" src=https://KasterMist.com/images/vscode.jpeg loading=lazy width=474 height=220></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/vscode/1/>Vscode 插件: C/C++</a><div class="post-meta mt-2"><span class=post-date>May 9, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt=Vim src=https://KasterMist.com/images/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim/>Vim</a><div class="post-meta mt-2"><span class=post-date>April 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/linux/linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/>Linux 常用命令</a><div class="post-meta mt-2"><span class=post-date>April 4, 2024</span></div></div></div></li></ul></div></div></div></div></div><div class="accordion post-toc d-none d-lg-block"><div class="accordion-item row mb-4 card component" id=postTOC><div class="card-header accordion-header"><h2 class="card-title fs-4 my-2 text-surface d-none d-lg-block">Contents</h2><a class="accordion-button d-lg-none mb-1 collapsed shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#post-toc aria-expanded=false aria-controls=post-toc>Contents</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block" id=post-toc><nav id=TableOfContents><ul><li><ul><li><a href=#使用线程实现gpu上的矢量求和>使用线程实现GPU上的矢量求和</a></li><li><a href=#在gpu上对更长的矢量求和>在GPU上对更长的矢量求和</a></li><li><a href=#在gpu上对任意长度的矢量求和>在GPU上对任意长度的矢量求和</a></li><li><a href=#共享内存和同步>共享内存和同步</a></li></ul></li></ul></nav></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="social-share mb-4 d-flex overflow-auto"><a class="btn-social-share d-flex flex-column align-items-center me-3" rel="noopener noreferrer" aria-label="Twitter Share Button" target=_blank href="https://twitter.com/intent/tweet?title=404%20Page%20not%20found&url=https%3a%2f%2fKasterMist.com%2f404.html"><i class="fab fa-2x fa-fw fa-twitter mb-2"></i> Twitter
</a><a class="btn-social-share d-flex flex-column align-items-center me-3" rel="noopener noreferrer" aria-label="Facebook Share Button" target=_blank href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fKasterMist.com%2f404.html"><i class="fab fa-2x fa-fw fa-facebook-f mb-2"></i> Facebook</a></div><hr class=mb-4><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Hugo Bootstrap Skeleton</p><p class="text-secondary mb-2"><small>An extreme fast, responsive and feature-rich blog theme for Hugo</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2016-2024 Razon Yang. All Rights Reserved.</small></div><div class="powered-by mb-2 text-secondary"><small>Build with ❤️ from the <a class=text-primary href=https://gohugo.io target=_blank rel="noopener noreferrer">Hugo</a> and the <a class=text-primary href=https://github.com/razonyang/hugo-theme-bootstrap target=_blank rel="noopener noreferrer">HBS</a> theme.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.db72e48588b8e652b8955c391c2388ae0ae61a325f72c2237daa71f4a1e545ab.js integrity="sha256-23LkhYi45lK4lVw5HCOIrgrmGjJfcsIjfapx9KHlRas=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.0a0d0099935beee41b7a7bf4543cd55e793e5f830a571b0794ef8c3602c5823c.js integrity="sha256-Cg0AmZNb7uQbenv0VDzVXnk+X4MKVxsHlO+MNgLFgjw=" crossorigin=anonymous defer></script><script src=/js/sw-register.js defer></script></body></html>