<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=auto data-palette=blue-gray><head><script src=/assets/init/bundle.min.42c0ed0dd5baeee307cec45b585e1906f653d7af06a8a6fed3b5e07dc0b1d906.js integrity="sha256-QsDtDdW67uMHzsRbWF4ZBvZT168GqKb+07XgfcCx2QY=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>CUDA学习(七) - Hugo Bootstrap Skeleton</title>
<link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_hued455efa02907b87d2b1b942bf7f6bdc_1081790_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Hugo,Bootstrap,Blog Theme"><meta name=description content="在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。
页锁定(Page-Locked)主机内存 CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。
由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。
事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，**每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。**计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。
然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。
下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。
float cuda_malloc_test(int size, bool up){ cudaEvent_t start, stop; int *a, *dev_a; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;stop)); a = (int*)malloc(size * sizeof(*a)); HANDLE_NULL(a); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_a, size * sizeof(&amp;dev_a))); HANDLE_ERROR(cuddaEventRecord(start, 0)); //为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器 for(int i = 0; i < 100; i++){ if(up){ HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(*dev_a), cudaMemcpyHostToDevice)); } else{ HANDLE_ERROR(cudaMemcpy(a, dev_a, size * sizeof(*dev_a), cudaMemcpyDeviceToHost)); } } HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop)); free(a); HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); return elapsedTime; } 函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。"><meta name=robots content="index, follow"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA学习(七)"><meta name=twitter:description content="在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。
页锁定(Page-Locked)主机内存 CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。
由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。
事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，**每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。**计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。
然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。
下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。
float cuda_malloc_test(int size, bool up){ cudaEvent_t start, stop; int *a, *dev_a; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;stop)); a = (int*)malloc(size * sizeof(*a)); HANDLE_NULL(a); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_a, size * sizeof(&amp;dev_a))); HANDLE_ERROR(cuddaEventRecord(start, 0)); //为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器 for(int i = 0; i < 100; i++){ if(up){ HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(*dev_a), cudaMemcpyHostToDevice)); } else{ HANDLE_ERROR(cudaMemcpy(a, dev_a, size * sizeof(*dev_a), cudaMemcpyDeviceToHost)); } } HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop)); free(a); HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); return elapsedTime; } 函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。"><meta property="og:url" content="https://KasterMist.com/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%83/"><meta property="og:site_name" content="Hugo Bootstrap Skeleton"><meta property="og:title" content="CUDA学习(七)"><meta property="og:description" content="在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。
页锁定(Page-Locked)主机内存 CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。
由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。
事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，**每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。**计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。
然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。
下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。
float cuda_malloc_test(int size, bool up){ cudaEvent_t start, stop; int *a, *dev_a; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;amp;stop)); a = (int*)malloc(size * sizeof(*a)); HANDLE_NULL(a); HANDLE_ERROR(cudaMalloc((void**)&amp;amp;dev_a, size * sizeof(&amp;amp;dev_a))); HANDLE_ERROR(cuddaEventRecord(start, 0)); //为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器 for(int i = 0; i &amp;lt; 100; i++){ if(up){ HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(*dev_a), cudaMemcpyHostToDevice)); } else{ HANDLE_ERROR(cudaMemcpy(a, dev_a, size * sizeof(*dev_a), cudaMemcpyDeviceToHost)); } } HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;amp;elapsedTime, start, stop)); free(a); HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); return elapsedTime; } 函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-28T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-28T00:00:00+00:00"><meta property="article:tag" content="CUDA"><meta itemprop=name content="CUDA学习(七)"><meta itemprop=description content="在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。
页锁定(Page-Locked)主机内存 CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。
由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。
事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，**每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。**计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。
然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。
下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。
float cuda_malloc_test(int size, bool up){ cudaEvent_t start, stop; int *a, *dev_a; float elapsedTime; HANDLE_ERROR(cudaEventCreate(&amp;start)); HANDLE_ERROR(cudaEventCreate(&amp;stop)); a = (int*)malloc(size * sizeof(*a)); HANDLE_NULL(a); HANDLE_ERROR(cudaMalloc((void**)&amp;dev_a, size * sizeof(&amp;dev_a))); HANDLE_ERROR(cuddaEventRecord(start, 0)); //为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器 for(int i = 0; i < 100; i++){ if(up){ HANDLE_ERROR(cudaMemcpy(dev_a, a, size * sizeof(*dev_a), cudaMemcpyHostToDevice)); } else{ HANDLE_ERROR(cudaMemcpy(a, dev_a, size * sizeof(*dev_a), cudaMemcpyDeviceToHost)); } } HANDLE_ERROR(cudaEventRecord(stop, 0)); HANDLE_ERROR(cudaEventSynchronize(stop)); HANDLE_ERROR(cudaEventElapsedTime(&amp;elapsedTime, start, stop)); free(a); HANDLE_ERROR(cudaFree(dev_a)); HANDLE_ERROR(cudaEventDestroy(start)); HANDLE_ERROR(cudaEventDestroy(stop)); return elapsedTime; } 函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。"><meta itemprop=datePublished content="2024-02-28T00:00:00+00:00"><meta itemprop=dateModified content="2024-02-28T00:00:00+00:00"><meta itemprop=wordCount content="917"><meta itemprop=keywords content="CUDA"><meta property="og:image" content="https://KasterMist.com/images/logo.png"><meta name=twitter:image content="https://KasterMist.com/images/logo.png"><meta property="og:image:alt" content="CUDA学习(七)"><meta name=twitter:image:alt content="CUDA学习(七)"><link rel=manifest href=/manifest.json><link data-precache rel=stylesheet href="/assets/main/bundle.min.c91211bab9a27752a04f0e67395e2f71bac30e8143bec4463bc91b3705056a70.css" integrity="sha256-yRIRurmid1KgTw5nOV4vcbrDDoFDvsRGO8kbNwUFanA=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.eb914844636cd41f221f109e99c887bbc3b6b5ffb2af7c664b284cea2d1b54b7.css integrity="sha256-65FIRGNs1B8iHxCemciHu8O2tf+yr3xmSyhM6i0bVLc=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://KasterMist.com/><picture><img class=logo alt=Logo src="https://KasterMist.com/images/logo.webp?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy width=956 height=956>
</picture>Main Page</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Main Page</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-6 col-xxl-auto"><a class="nav-link py-2 px-0 px-xxl-2" href=https://KasterMist.com/docs/><span class="menu-icon me-1"><i class="fas fa-fw fa-file"></i></span>Docs</a></li><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><h6 class=dropdown-header>Blog Menu Description</h6></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://KasterMist.com/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li><li class="nav-item col-6 col-xxl-auto"><a class="nav-link py-2 px-0 px-xxl-2" href=https://hbs.razonyang.com/v1/en/docs/ target=_blank rel="noopener noreferrer"><span class="menu-icon me-1"><i class="fas fa-fw fa-book"></i></span>Documentations</a></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/KasterMist title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-adjust" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class=mode-item data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class="mode-item active" data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/posts/>Posts</a></li><li class="breadcrumb-item active">CUDA学习(七)</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action btn-reward" role=button data-bs-toggle=modal data-bs-target=#rewardModal title="Buy me a coffee"><i class="fas fa-fw fa-coffee"></i>
</a><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-copyright" href=#post-copyright role=button aria-label=Copyright title=Copyright><i class="fas fa-fw fa-copyright"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">CUDA学习(七)</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2024-02-28 00:00:00 +0000 UTC.">February 28, 2024</span><span class="post-reading-time me-1 mb-1">5 min read</span><a href=/categories/tutorial/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Tutorial</a><a href=/tags/cuda/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">CUDA</a></div><div class="mt-2 mb-3 d-block d-xxl-none"><h2 class="text-surface mb-3">Contents</h2><div id=post-toc-container></div><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>在并行环境中，任务可以是任意操作。例如，应用程序可以执行两个任务：其中一个线程重绘程序的GUI，而另一个线程通过网络下载更新包。这些任务并行执行，彼此之间没有任何共同的地方。虽然GPU上的任务并行性并不像CPU上的任务并行性那样灵活，但仍然可以进一步提高程序在GPU上的运行速度。本章将介绍CUDA流，以及如何通过流在GPU上同时执行多个任务。</p><h2 id=页锁定page-locked主机内存 data-numberify>页锁定(Page-Locked)主机内存<a class="anchor ms-1" href=#页锁定page-locked主机内存></a></h2><p>CUDA提供了自己独有的机制来分配主机内存：cudaHostAlloc()。malloc()分配的内存与cudaHostAlloc()分配的内存之间存在一个重要差异。C库函数malloc()将分配标准的、可分页的(Pagable)主机内存，而cudaHostAlloc()将分配页锁定的主机内存。页锁定内存也称为固定内存(Pinned Memory)或者不可分页内存，它有一个重要属性：操作系统将不会对这块内存分页并交还到磁盘上，从而确保了该内存始终驻留在物理内存中。因此，操作系统能够安全地使某个应用程序访问该内存的物理地址，因为这块内存将不会被破坏或者重新定位。</p><p>由于GPU知道内存的物理地址，因此可以通过“直接内存访问（Direct Memory Access，DMA）”技术来在GPU和主机之间复制数据。由于DMA在执行复制时无需CPU的介入，这也就意味着，CPU很可能在DMA的执行过程中将目标内存交换到磁盘上，或者通过更新操作系统的分页来重新定位目标内存的物理地址。CPU可能会移动可分页的数据，这就可能对DMA操作造成延迟。因此，在DMA复制过程中使用固定内存时非常重要的。</p><p>事实上，当使用可分页内存进行复制时，CUDA驱动程序仍然会通过DAM把数据传输给GPU。因此，复制操作将执行两遍，第一遍从可分页内存复制到一块“临时的”页锁定内存，然后再从这个页锁定内存复制到GPU上。因此，**每当从可分页内存中执行复制操作时，复制速度将受限于PCIE（高速串行计算机扩展总线标准）传输速度和系统前端总线速度相对较低的一方。当在GPU和主机间复制数据时，这种差异会使页锁定主机内存的性能比标准可分页内存的性能要高达约2倍。**计时PCIE的速度与前端总线的速度相等，由于可分页内存需要更多一次由CPU参与的复制操作，因此会带来额外的开销。</p><p>然而，使用cudaHostAlloc()分配固定内存时，将失去虚拟内存的所有功能。特别是在应用程序中使用每个页锁定内存时都需要分配物理内存，因为这些内存不能交换到磁盘上。这意味着与使用标准的malloc()调用相比，系统将更快地耗尽内存。因此，应用程序在物理内存较少的机器上会运行失败，而且意味着应用程序将影响在系统上运行的其他应用程序的性能。建议仅对cudaMemcpy()调用中的源内存或者目标内存才使用页锁定内存，并且在不再需要使用它们时立即释放，而不是等到应用程序关闭时才释放。</p><p>下面给的例子来说明如何分配固定内存，以及它相对于标准可分页内存的性能优势。这个例子主要是测试cudaMemcpy()在可分配内存和页锁定内存上的性能。我们要做的就是分配一个GPU缓冲区以及一个大小相等的主机缓冲区，然后两个缓冲区之间执行一些复制操作（从主机到设备、从设备到主机）。为了获得精确的时间统计，我们为复制操作的起始时刻和结束时刻分别设置了CUDA事件。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>float</span> <span class=nf>cuda_malloc_test</span><span class=p>(</span><span class=kt>int</span> <span class=n>size</span><span class=p>,</span> <span class=kt>bool</span> <span class=n>up</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>a</span> <span class=o>=</span> <span class=p>(</span><span class=kt>int</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_NULL</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cuddaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//为size个整数分别分配主机缓冲区和GPU缓冲区，然后执行100次复制操作，并由参数up来指定复制方向，在完成复制操作后停止计时器
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>100</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>up</span><span class=p>){</span>
</span></span><span class=line><span class=cl>            <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>dev_a</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>dev_a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>dev_a</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsedTime</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>free</span><span class=p>(</span><span class=n>a</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>函数cuda_malloc_test()通过标准的C函数malloc()来分配可分页主机内存，在分配固定内存时则使用了cudaHostAlloc()。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=kt>float</span> <span class=nf>cuda_host_alloc_test</span><span class=p>(</span><span class=kt>int</span> <span class=n>size</span><span class=p>,</span> <span class=kt>bool</span> <span class=n>up</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>a</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>dev_a</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>100</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span><span class=p>(</span><span class=n>up</span><span class=p>){</span>
</span></span><span class=line><span class=cl>            <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>dev_a</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpy</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>dev_a</span><span class=p>,</span> <span class=n>size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=o>*</span><span class=n>dev_a</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsedTime</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventDestroy</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>cudaHostAlloc()分配的内存与malloc()分配的内存在使用方式是相同的，与malloc()不同之处在于最后一个参数cudaHostAllocDefault。最后一个参数的取值范围是一组标志，我们可以通过这些标志来修改cudaHostAlloc()的行为，并分配不同形式的固定主机内存。就目前而言，只需使用默认值。最后需要使用cudaFreeHost()来释放内存。</p><p>main()函数的代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;../common/book.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#define SIZE (10 * 1024 * 1024)
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>MB</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=p>)</span><span class=mi>100</span> <span class=o>*</span> <span class=n>SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)</span> <span class=o>/</span> <span class=mi>1024</span> <span class=o>/</span> <span class=mi>1024</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>elapsedTime</span> <span class=o>=</span> <span class=nf>cuda_malloc_test</span><span class=p>(</span><span class=n>SIZE</span><span class=p>,</span> <span class=nb>true</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time using cudaMalloc: %3.1fms</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\t</span><span class=s>MB/s during copy up: %3.1f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>MB</span> <span class=o>/</span> <span class=p>(</span><span class=n>elapsedTime</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=c1>//要执行相反方向的性能，可以执行相同的调用，只需要将第二个参数指定为false
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>elapsedTime</span> <span class=o>=</span> <span class=nf>cuda_malloc_test</span><span class=p>(</span><span class=n>SIZI</span><span class=p>,</span> <span class=nb>false</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time using cudaMalloc: %3.1f ms </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\t</span><span class=s>MB/s during copy down: %3.1f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>MB</span> <span class=o>/</span> <span class=p>(</span><span class=n>elapsedTime</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//测试cudaHostAlloc()的性能
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>elapsedTime</span> <span class=o>=</span> <span class=nf>cuda_host_malloc_test</span><span class=p>(</span><span class=n>SIZE</span><span class=p>,</span> <span class=nb>true</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time using cudaHostMalloc: %3.1fms</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\t</span><span class=s>MB/s during copy up: %3.1f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>MB</span> <span class=o>/</span> <span class=p>(</span><span class=n>elapsedTime</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>elapsedTime</span> <span class=o>=</span> <span class=nf>cuda_host_malloc_test</span><span class=p>(</span><span class=n>SIZI</span><span class=p>,</span> <span class=nb>false</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time using cudaHostMalloc: %3.1f ms </span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;</span><span class=se>\t</span><span class=s>MB/s during copy down: %3.1f</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>MB</span> <span class=o>/</span> <span class=p>(</span><span class=n>elapsedTime</span> <span class=o>/</span> <span class=mi>1000</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=cuda流 data-numberify>CUDA流<a class="anchor ms-1" href=#cuda流></a></h2><p>之前介绍过cudaEventRecord()，并没有详细解释这个函数的第二个参数，这个第二个参数是用于指定插入事件的流(Stream)。CUDA流表示一个GPU操作队列，并且该队列中的操作将以指定的顺序执行。我们可以在流中添加一些操作，例如核函数启动、内存复制，以及时间的启动和结束等。你可以将每个流视为GPU上的一个任务，并且这些任务可以并行执行。我们将首先介绍如何使用流，然后介绍如何使用流来加速应用程序。</p><h3 id=使用单个cuda流 data-numberify>使用单个CUDA流<a class="anchor ms-1" href=#使用单个cuda流></a></h3><p>仅当使用多个流时才能显现出流的真正威力。不过我们先用一个流来说明用法。下面的示例中，我们将计算a中三个值和b中三个值的平均值。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;../common/book.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#define N (1024 * 1024)
</span></span></span><span class=line><span class=cl><span class=cp>#define FULL_DATA_SIZE (N * 20)
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>kernel</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>c</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>idx</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>idx1</span> <span class=o>=</span> <span class=p>(</span><span class=n>idx</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>idx2</span> <span class=o>=</span> <span class=p>(</span><span class=n>idx</span> <span class=o>+</span> <span class=mi>2</span><span class=p>)</span> <span class=o>%</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>float</span> <span class=n>as</span> <span class=o>=</span> <span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>+</span> <span class=n>a</span><span class=p>[</span><span class=n>idx1</span><span class=p>]</span> <span class=o>+</span> <span class=n>a</span><span class=p>[</span><span class=n>idx2</span><span class=p>])</span> <span class=o>/</span> <span class=mf>3.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>float</span> <span class=n>bs</span> <span class=o>=</span> <span class=p>(</span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>idx1</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>idx2</span><span class=p>])</span> <span class=o>/</span> <span class=mf>3.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>as</span> <span class=o>+</span> <span class=n>bs</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=c1>//选择一个一个支持设备重叠功能的设备。支持设备重叠功能的GPU能够在执行一个CUDA C核函数的同时，
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=c1>//还能在设备与主机之间执行复制操作。	
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>cudaDeviceProp</span> <span class=n>prop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>whichDevice</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDevice</span><span class=p>(</span><span class=o>&amp;</span><span class=n>whichDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDeviceProperties</span><span class=p>(</span><span class=o>&amp;</span><span class=n>prop</span><span class=p>,</span> <span class=n>whichDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=o>!</span><span class=n>prop</span><span class=p>.</span><span class=n>deviceOverlap</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Device will not handle overlaps, so no speed up from streams</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//启动计时器
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//初始化流
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>cudaStream_t</span> <span class=n>stream</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stream</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//数据分配操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=o>*</span><span class=n>host_a</span><span class=p>,</span> <span class=o>*</span><span class=n>host_b</span><span class=p>,</span> <span class=o>*</span><span class=n>host_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=o>*</span><span class=n>dev_a</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//在GPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_c</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//分配由流使用的页锁定内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>host_a</span><span class=p>,</span> <span class=n>FULL_DATA_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>host_b</span><span class=p>,</span> <span class=n>FULL_DATA_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>host_c</span><span class=p>,</span> <span class=n>FULL_DATA_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>FULL_DATA_SIZE</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>host_a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=nf>rand</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=n>host_b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=nf>rand</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p>程序将使用主机上的固定内存。我们还会使用一种新的cudaMemcpy()函数，并且在这个新函数中需要页锁定主机内存。在分配完输入内存后，调用C的库函数rand()并用随机证书填充主机内存。</p><p>执行计算的方式是将两个输入缓冲区复制到GPU，启动核函数，然后将输出缓冲区复制回主机。不过，本示例做出了小的调整。首先，我们不将输入缓冲区整体都复制到GPU，而是将输入缓冲区划分为更小的块，并在每个块上执行一个包含三个步骤的过程。我们将一部分输入缓冲区复制到GPU，在这部分缓冲区上运行核函数，然后将输出缓冲区的这部分结果复制回主机。下面给出了一个需要这种方法的情形：GPU的内存远少于主机内存，由于整个缓冲区无法一次性填充到GPU，因此需要分块进行计算。执行“分块”计算的代码如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=c1>//在整体数据上循环，每个数据块的大小为N
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>FULL_DATA_SIZE</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=c1>//将锁定内存以异步的方式复制到设备上
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>host_a</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_b</span><span class=p>,</span> <span class=n>host_b</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>N</span> <span class=o>/</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>stream</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a</span><span class=p>,</span> <span class=n>dev_b</span><span class=p>,</span> <span class=n>dev_c</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>//将数据从设备复制到锁定内存
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>host_c</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>dev_c</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>.</span> <span class=n>stream</span><span class=p>));</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span></code></pre></div><p>上述代码使用cudaMemcpyAsync()在GPU与主机之间复制数据。cudaMemcpy()的行为类似于C库函数memcpy()，尤其是这个函数将以同步的方式进行。这意味着当函数返回时，复制操作就已经完成，并且在输出缓冲区中包含了复制进去的内容。异步函数的行为与同步函数相反，在调用cudaMemcpyAsync()时，只是放置一个请求，表示在流中执行一次内存复制操作，这个流时通过参数stream来指定的。当函数返回时，我们无法确保复制操作是否已经启动，更无法保证它是否已经结束。**我们能够得到的保证是，复制操作肯定会将肯定会当下一个被放入流中的操作之前执行。**任何传递给cudaMemcpyAsync()的主机内存指针都必须已经通过cudaHostAlloc()分配好内存。也就是，<strong>你只能以异步方式对页锁定内存进行复制操作。</strong></p><p>在核函数调用的尖括号中还可以带有一个流参数。此时核函数调用将是异步的。从技术上来说，当循环迭代完一次时，有可能不会启动任何内存复制或核函数执行。<strong>我们能够确保的是，第一次放入流中的复制操作将在第二次复制操作之前执行。此外，第二个复制操作将在核函数启动之前完成。而核函数将在第三次复制操作开始之前完成。</strong></p><p>当for循环结束时，在队列中应该包含了许多等待GPU执行的工作。如果想要确保GPU执行完了计算和内存复制等操作，那么就需要将GPU与主机同步。也就是说，主机在继续执行之前，要首先等待GPU执行完成。可以调用cudaStreamSynchronize()并制定想要等待的流。当程序执行到stream与主机同步之后的代码时，所有的计算和复制操作都已经完成，因此停止计时器，收集性能数据，并释放输入缓冲区和输出缓冲区。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=c1>//将计算结果从页锁定内存复制到主机内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamSynchronize</span><span class=p>(</span><span class=n>stream</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsedTime</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time taken: 3.1%f ms</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//释放流和内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>host_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>host_b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>host_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//销毁对GPU操作进行排队的流
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamDestroy</span><span class=p>(</span><span class=n>stream</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=使用多个cuda流 data-numberify>使用多个CUDA流<a class="anchor ms-1" href=#使用多个cuda流></a></h3><p>我们将上面的示例改为使用两个不同的流。我们将实现：在第0个流执行核函数的同时，第1个流将输入缓冲区复制到GPU。然后在第0个流将计算结果复制回主机的同时，第1个流将执行核函数。接着，第1个流将计算结果复制回主机，同时第0个流开始在下一块数据上执行核函数。假设内存复制操作和核函数执行的事件大致相同，那么应用程序的执行时间线将如图下所示（后续图片中函数调用cudaMemcpyAsync()被简写为复制）：</p><p><picture><img class=img-fluid alt=CUDA_7_1 src="https://KasterMist.com/CUDA/CUDA_7_1.png?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy width=990 height=940></picture></p><p>核函数的代码保持不变。与使用单个流的版本一样，我们将判断设备是否支持计算与内存复制操作的重叠。如果设备支持重叠，那么就像前面一样创建CUDA事件并对应用程序计时。创建两个流的方式与之前代码中创建单个流的方式是一样的。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&#34;../common/book.h&#34;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=cp>#define N (1024 * 1024)
</span></span></span><span class=line><span class=cl><span class=cp>#define FULL_DATA_SIZE (N * 20)
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>kernel</span><span class=p>(</span><span class=kt>int</span> <span class=o>*</span><span class=n>a</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>b</span><span class=p>,</span> <span class=kt>int</span> <span class=o>*</span><span class=n>c</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>idx</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=n>idx</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>idx1</span> <span class=o>=</span> <span class=p>(</span><span class=n>idx</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>int</span> <span class=n>idx2</span> <span class=o>=</span> <span class=p>(</span><span class=n>idx</span> <span class=o>+</span> <span class=mi>2</span><span class=p>)</span> <span class=o>%</span> <span class=mi>256</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>float</span> <span class=n>as</span> <span class=o>=</span> <span class=p>(</span><span class=n>a</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>+</span> <span class=n>a</span><span class=p>[</span><span class=n>idx1</span><span class=p>]</span> <span class=o>+</span> <span class=n>a</span><span class=p>[</span><span class=n>idx2</span><span class=p>])</span> <span class=o>/</span> <span class=mf>3.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=kt>float</span> <span class=n>bs</span> <span class=o>=</span> <span class=p>(</span><span class=n>b</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>idx1</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>idx2</span><span class=p>])</span> <span class=o>/</span> <span class=mf>3.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=n>c</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>=</span> <span class=p>(</span><span class=n>as</span> <span class=o>+</span> <span class=n>bs</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=nf>main</span><span class=p>(){</span>
</span></span><span class=line><span class=cl>    <span class=n>cudaDeviceProp</span> <span class=n>prop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>whichDevice</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDevice</span><span class=p>(</span><span class=o>&amp;</span><span class=n>whichDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaGetDeviceProperties</span><span class=p>(</span><span class=o>&amp;</span><span class=n>prop</span><span class=p>,</span> <span class=n>whichDevice</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span><span class=p>(</span><span class=o>!</span><span class=n>prop</span><span class=p>.</span><span class=n>deviceOverlap</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Device will not handle overlaps, so no speed up from streams</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=kt>cudaEvent_t</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>elapsedTime</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//启动计时器
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>start</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>start</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//初始化流
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>cudaStream_t</span> <span class=n>stream0</span><span class=p>,</span> <span class=n>stream1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamCreate</span><span class=p>(</span><span class=o>&amp;</span><span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//数据分配操作
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=o>*</span><span class=n>host_a</span><span class=p>,</span> <span class=o>*</span><span class=n>host_b</span><span class=p>,</span> <span class=o>*</span><span class=n>host_c</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=o>*</span><span class=n>dev_a0</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b0</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_c0</span><span class=p>;</span> <span class=c1>//为第0个流分配的GPU内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>int</span> <span class=o>*</span><span class=n>dev_a1</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_b1</span><span class=p>,</span> <span class=o>*</span><span class=n>dev_c1</span><span class=p>;</span> <span class=c1>//为第1个流分配的GPU内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    
</span></span><span class=line><span class=cl>    <span class=c1>//在GPU上分配内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a0</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_b0</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_c0</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_a1</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_b1</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMalloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>dev_c1</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>)));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//分配由流使用的页锁定内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>host_a</span><span class=p>,</span> <span class=n>FULL_DATA_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>host_b</span><span class=p>,</span> <span class=n>FULL_DATA_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaHostAlloc</span><span class=p>((</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>host_c</span><span class=p>,</span> <span class=n>FULL_DATA_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaHostAllocDefault</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>FULL_DATA_SIZE</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=n>host_a</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=nf>rand</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=n>host_b</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=nf>rand</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p>之后，程序在输入数据块上循环。然而，由于现在使用了两个流，因此在for()循环的迭代中需要处理的数据量也是原来的两倍。在stream()中，我们首先将a和b的异步复制操作放入GPU的队列，然后将一个核函数执行放入队列，接下来再将一个复制回c的操作放入队列：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>    <span class=c1>//在整体数据上循环，每个数据块的大小为N
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>FULL_DATA_SIZE</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=n>N</span> <span class=o>*</span> <span class=mi>2</span><span class=p>){</span>
</span></span><span class=line><span class=cl>        <span class=c1>//将锁定内存以异步方式复制到设备上
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_a0</span><span class=p>,</span> <span class=n>host_a</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_b0</span><span class=p>,</span> <span class=n>host_b</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>N</span> <span class=o>/</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>stream0</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a0</span><span class=p>,</span> <span class=n>dev_b0</span><span class=p>,</span> <span class=n>dev_c0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>//将数据从设备复制回锁定内存
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>host_c</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>dev_c0</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>//在将这些操作放入stream0队列后，再把下一个数据块上的相同操作放入stream1的队列中
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>        <span class=c1>//将锁定内存以异步方式复制到设备上
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_a1</span><span class=p>,</span> <span class=n>host_a</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=n>N</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_b1</span><span class=p>,</span> <span class=n>host_b</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=n>N</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>        <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>N</span> <span class=o>/</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>stream1</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a1</span><span class=p>,</span> <span class=n>dev_b1</span><span class=p>,</span> <span class=n>dev_c1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>//将数据从设备复制回锁定内存
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>host_c</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=n>N</span><span class=p>,</span> <span class=n>dev_c1</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span></code></pre></div><p>这样，在for循环的迭代过程中，将交替地把每个数据块放入这两个流的队列，直到所有待处理的输入数据都被放入队列。在结束了for循环后，在停止应用程序的计时器之前，首先将GPU与GPU进行同步，由于使用了两个流，因此要对二者都进行同步。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>	<span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamSynchronize</span><span class=p>(</span><span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>	<span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamSynchronize</span><span class=p>(</span><span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventRecord</span><span class=p>(</span><span class=n>stop</span><span class=p>,</span> <span class=mi>0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventSynchronize</span><span class=p>(</span><span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaEventElapsedTime</span><span class=p>(</span><span class=o>&amp;</span><span class=n>elapsedTime</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;Time taken: 3.1%f ms</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>elapsedTime</span><span class=p>);</span>
</span></span><span class=line><span class=cl>	
</span></span><span class=line><span class=cl>	<span class=c1>//释放流和内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>host_a</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>host_b</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFreeHost</span><span class=p>(</span><span class=n>host_c</span><span class=p>));</span>
</span></span><span class=line><span class=cl>	<span class=c1>//销毁两个流，释放两倍的GPU内存
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_b0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_c0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>	<span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_a1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_b1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaFree</span><span class=p>(</span><span class=n>dev_c1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>//销毁对GPU操作进行排队的流
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamDestroy</span><span class=p>(</span><span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>	<span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaStreamDestroy</span><span class=p>(</span><span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h3 id=gpu的工作调度机制 data-numberify>GPU的工作调度机制<a class="anchor ms-1" href=#gpu的工作调度机制></a></h3><p>我们可以将流视为有序的操作序列，其中既包含内存复制操作，又包含核函数调用。下图将展示任务调度情形。</p><p><picture><img class=img-fluid alt=CUDA_7_2 src="https://KasterMist.com/CUDA/CUDA_7_2.png?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy width=1136 height=886></picture></p><p>从图中得到，第0个流对A的内存复制需要在对B的内存复制之前完成，而对B的复制又要在核函数A启动之前完成。然而，一旦这些操作放入到硬件的内存复制引擎和核函数执行引擎的队列中时，这些依赖性将丢失，因此CUDA驱动程序需要确保硬件的执行单元不破坏流内部的依赖性。</p><p>从之前的代码中可以得知，应用程序基本上是对a调用一次cudaMemcpyAsync()，对b调用一次cudaMemcpyAsync()，然后再是执行核函数以及调用cudaMemcpyAsync()将c复制回主机。应用程序首先将第0个流的所有操作放入队列，然后是第1个流的所有操作。CUDA驱动程序负责按照这些操作的顺序把他们调度到硬件上执行，这就维持了流内部的依赖性。下图体现了这些依赖性，其中从复制操作到核函数的箭头表示，复制操作要等核函数执行完成之后才能开始。</p><p><picture><img class=img-fluid alt=CUDA_7_3 src="https://KasterMist.com/CUDA/CUDA_7_3.png?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy width=1200 height=666></picture></p><p>假定理解了GPU的工作调度远离后，我们可以得到关于这些操作在硬件上执行的时间线，如下图所示：</p><p><picture><img class=img-fluid alt=CUDA_7_4 src="https://KasterMist.com/CUDA/CUDA_7_4.png?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy width=1152 height=820></picture></p><p>由于第0个流中将c复制回主机的操作要等待核函数执行完成，因此第1个流中将a和b复制到GPU的操作虽然是完全独立的，但却被阻塞了，这是因为GPU引擎是按照指定的顺序来执行工作。这种情况很好地说明了为什么在程序中使用了两个流却无法获得加速的窘境。这个问题的直接原因是我们没有意识到硬件的工作方式与CUDA流编程模型的方式是不同的。</p><h3 id=高效地使用多个cuda流 data-numberify>高效地使用多个CUDA流<a class="anchor ms-1" href=#高效地使用多个cuda流></a></h3><p>从上面的说明可以得出，如果同时调度某个流的所有操作，那么很容易在无意中阻塞另一个流的复制操作或者核函数执行。要解决这个问题，在将操作放入流的队列时应采用宽度优先的方式，而非深度优先的方式。<strong>也就是说不是首先添加第0个流的所有四个操作（即a的复制、b的复制、核函数以及c的复制），然后不再添加第1个流的所有四个操作，而是将这两个流之间的操作交叉添加。</strong></p><p>首先，将a的复制操作添加到第0个流，然后将a的复制操作添加到第1个流。接着，将b的复制操作添加到第0个流，再将b的复制操作添加到第1个流。接下来，将核函数调用添加到第0个流，再将相同的操作添加到第1个流中。最后，将c的复制操作添加到第0个流中，然后将相同的操作添加到第1个流中。</p><p>下面是实际的代码。我们的修改仅限于for循环中的两个流的处理，采用宽度优先方式将操作分配到两个流的代码如下：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=k>for</span><span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>FULL_DATA_SIZE</span><span class=p>;</span> <span class=n>i</span> <span class=o>+=</span> <span class=n>N</span> <span class=o>*</span> <span class=mi>2</span><span class=p>){</span>
</span></span><span class=line><span class=cl>    <span class=c1>//将复制a的操作放入stream0和stream1的队列
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_a0</span><span class=p>,</span> <span class=n>host_a</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_a1</span><span class=p>,</span> <span class=n>host_a</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=n>N</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//将复制b的操作放入stream0和stream1的队列
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_b0</span><span class=p>,</span> <span class=n>host_b</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>dev_b1</span><span class=p>,</span> <span class=n>host_b</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=n>N</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyHostToDevice</span><span class=p>,</span> <span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//将核函数的执行放入stream0和stream1的队列中
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>N</span> <span class=o>/</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>stream0</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a0</span><span class=p>,</span> <span class=n>dev_b0</span><span class=p>,</span> <span class=n>dev_c0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>kernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>N</span> <span class=o>/</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>stream1</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>dev_a1</span><span class=p>,</span> <span class=n>dev_b1</span><span class=p>,</span> <span class=n>dev_c1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>//将复制c的操作放入stream0和stream1的队列
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>host_c</span> <span class=o>+</span> <span class=n>i</span><span class=p>,</span> <span class=n>dev_c0</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>,</span> <span class=n>stream0</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>HANDLE_ERROR</span><span class=p>(</span><span class=nf>cudaMemcpyAsync</span><span class=p>(</span><span class=n>host_c</span> <span class=o>+</span> <span class=n>i</span> <span class=o>+</span> <span class=n>N</span><span class=p>,</span> <span class=n>dev_c1</span><span class=p>,</span> <span class=n>N</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>int</span><span class=p>),</span> <span class=n>cudaMemcpyDeviceToHost</span><span class=p>,</span> <span class=n>stream1</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>此时，新的执行时间线将如下图所示：</p><p><picture><img class=img-fluid alt=CUDA_7_5 src="https://KasterMist.com/CUDA/CUDA_7_5.png?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy width=1126 height=640></picture></p></div></div><div class="modal fade" id=rewardModal tabindex=-1 aria-labelledby=rewardModalLabel aria-hidden=true><div class=modal-dialog><div class="modal-content surface"><div class=modal-header><h5 class="modal-title text-surface" id=rewardModalLabel><i class="fas fa-fw fa-coffee me-1"></i>Buy me a coffee</h5><a href=# data-bs-dismiss=modal class=btn-close aria-label=Close></a></div><div class=modal-body><ul class="nav nav-tabs mb-3" role=tablist><li class="nav-item text-nowrap" role=presentation><a class="nav-link active" id=reward-alipay-tab data-bs-toggle=tab href=#reward-alipay role=tab aria-controls=reward-alipay aria-selected=true><i class="fab fa-fw fa-alipay me-1"></i>Alipay</a></li><li class="nav-item text-nowrap" role=presentation><a class=nav-link id=reward-wechat-tab data-bs-toggle=tab href=#reward-wechat role=tab aria-controls=reward-wechat aria-selected=true><i class="fab fa-fw fa-weixin me-1"></i>WeChat</a></li></ul><div class=tab-content id=rewardTabContent><div class="tab-pane fade post-reward-content text-center show active" id=reward-alipay role=tabpanel aria-labelledby=reward-alipay-tab><img class="img-fluid post-reward-img" src=https://KasterMist.com/images/reward/alipay.jpg loading=lazy data-viewer-invisible></div><div class="tab-pane fade post-reward-content text-center show" id=reward-wechat role=tabpanel aria-labelledby=reward-wechat-tab><img class="img-fluid post-reward-img" src=https://KasterMist.com/images/reward/wechat.jpg loading=lazy data-viewer-invisible></div></div></div></div></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AD/>CUDA学习(六)</a></div><div class="post-nav post-next"><a href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AB/>CUDA学习(八)</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><div class="post-copyright mb-3 row card component" id=post-copyright><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Copyright</h2></div><div class=card-body><a class="d-flex align-items-center flex-column" target=_blank rel="license noopener noreferrer" href=https://creativecommons.org/licenses/by-nc-nd/4.0/deed.en><span><i class="fab fa-fw fa-2x fa-creative-commons"></i><i class="fab fa-fw fa-2x fa-creative-commons-by"></i><i class="fab fa-fw fa-2x fa-creative-commons-nc"></i><i class="fab fa-fw fa-2x fa-creative-commons-nd"></i></span>
CC BY-NC-ND 4.0</a></div></div><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%85%AD/>CUDA学习(六)</a><div class="post-meta mb-0">February 27, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%BA%94/>CUDA学习(五)</a><div class="post-meta mb-0">February 23, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E5%9B%9B/>CUDA学习(四)</a><div class="post-meta mb-0">February 18, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%B8%89/>CUDA学习(三)</a><div class="post-meta mb-0">February 12, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/posts/cuda/cuda%E5%AD%A6%E4%B9%A0-%E4%BA%8C/>CUDA学习(二)</a><div class="post-meta mb-0">February 8, 2024</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Kaster Mist" src="https://KasterMist.com/images/profile.webp?v=27df3ae9eab0088f88134ceeb739fb20" loading=lazy data-viewer-invisible width=956 height=956></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Kaster Mist</div><div class=profile-company><i class="fas fa-fw fa-building"></i>ShonCloud</div><div class=profile-location><i class="fas fa-fw fa-map-marker-alt"></i>China</div><a class="profile-about text-primary" href=/about/><i class="fas fa-fw fa-user"></i>About</a><a class="profile-contact text-primary" href=/contact/><i class="fas fa-fw fa-question-circle"></i>Contact Us</a></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:KasterMist@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/KasterMist title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://www.linkedin.com/in/letian-xie-8a0886282/ title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/tutorial/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Tutorial>Tutorial
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/categories/note/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Note>Note
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/categories/draft/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Draft>Draft
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/cuda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=CUDA>CUDA
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/tags/linux/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Linux>Linux
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/linux-command/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Linux Command">Linux Command
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/git/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Git>Git
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/hugo-bootstrap-skeleton/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Hugo Bootstrap Skeleton">Hugo Bootstrap Skeleton
<span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/tags/vscode/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=VsCode>VsCode
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">15</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt=Vim src=https://KasterMist.com/images/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim/>Vim</a><div class="post-meta mt-2"><span class=post-date>April 13, 2024</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/git/git_tutorial_1/>Git 学习 (一)</a><div class="post-meta mt-2"><span class=post-date>May 14, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/hugo_theme_usage_notes/hugo_bootstrap_skeleton/>Hugo Bootstrap Skeleton Notes</a><div class="post-meta mt-2"><span class=post-date>May 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt="Vscode 插件: C/C++" src=https://KasterMist.com/images/vscode.jpeg loading=lazy width=474 height=220></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/vscode/1/>Vscode 插件: C/C++</a><div class="post-meta mt-2"><span class=post-date>May 9, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><img class=img-fluid alt=Vim src=https://KasterMist.com/images/vim.png loading=lazy width=880 height=440></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/posts/linux/vim/>Vim</a><div class="post-meta mt-2"><span class=post-date>April 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center"><a class=post-title href=/posts/linux/linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/>Linux 常用命令</a><div class="post-meta mt-2"><span class=post-date>April 4, 2024</span></div></div></div></li></ul></div></div></div></div></div><div class="accordion post-toc d-none d-lg-block"><div class="accordion-item row mb-4 card component" id=postTOC><div class="card-header accordion-header"><h2 class="card-title fs-4 my-2 text-surface d-none d-lg-block">Contents</h2><a class="accordion-button d-lg-none mb-1 collapsed shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#post-toc aria-expanded=false aria-controls=post-toc>Contents</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block" id=post-toc><nav id=TableOfContents><ul><li><a href=#页锁定page-locked主机内存>页锁定(Page-Locked)主机内存</a></li><li><a href=#cuda流>CUDA流</a><ul><li><a href=#使用单个cuda流>使用单个CUDA流</a></li><li><a href=#使用多个cuda流>使用多个CUDA流</a></li><li><a href=#gpu的工作调度机制>GPU的工作调度机制</a></li><li><a href=#高效地使用多个cuda流>高效地使用多个CUDA流</a></li></ul></li></ul></nav></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="social-share mb-4 d-flex overflow-auto"><a class="btn-social-share d-flex flex-column align-items-center me-3" rel="noopener noreferrer" aria-label="Twitter Share Button" target=_blank href="https://twitter.com/intent/tweet?title=404%20Page%20not%20found&url=https%3a%2f%2fKasterMist.com%2f404.html"><i class="fab fa-2x fa-fw fa-twitter mb-2"></i> Twitter
</a><a class="btn-social-share d-flex flex-column align-items-center me-3" rel="noopener noreferrer" aria-label="Facebook Share Button" target=_blank href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fKasterMist.com%2f404.html"><i class="fab fa-2x fa-fw fa-facebook-f mb-2"></i> Facebook</a></div><hr class=mb-4><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Hugo Bootstrap Skeleton</p><p class="text-secondary mb-2"><small>An extreme fast, responsive and feature-rich blog theme for Hugo</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2016-2024 Razon Yang. All Rights Reserved.</small></div><div class="powered-by mb-2 text-secondary"><small>Build with ❤️ from the <a class=text-primary href=https://gohugo.io target=_blank rel="noopener noreferrer">Hugo</a> and the <a class=text-primary href=https://github.com/razonyang/hugo-theme-bootstrap target=_blank rel="noopener noreferrer">HBS</a> theme.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.db72e48588b8e652b8955c391c2388ae0ae61a325f72c2237daa71f4a1e545ab.js integrity="sha256-23LkhYi45lK4lVw5HCOIrgrmGjJfcsIjfapx9KHlRas=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.0a0d0099935beee41b7a7bf4543cd55e793e5f830a571b0794ef8c3602c5823c.js integrity="sha256-Cg0AmZNb7uQbenv0VDzVXnk+X4MKVxsHlO+MNgLFgjw=" crossorigin=anonymous defer></script><script src=/js/sw-register.js defer></script></body></html>